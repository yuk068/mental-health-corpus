{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4479228b-5e89-44a6-ab50-b0ed724f6520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF - Train shape: (18592, 3500), Test Shape: (4648, 3500)\n",
      "LSA - Train shape: (18592, 100), Test Shape: (4648, 100)\n",
      "\n",
      "CUDA is available. Running on GPU.\n",
      "GPU Name: NVIDIA GeForce RTX 3060\n",
      "CUDA Version: 12.1\n",
      "GPU Capability: (8, 6)\n",
      "Total GPU Memory: 12.88 GB\n",
      "CPU: 6 threads available\n",
      "PyTorch Version: 2.5.1\n"
     ]
    }
   ],
   "source": [
    "# Nhập thư viện\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Đọc bộ dữ liệu\n",
    "corpus = pd.read_csv('data/cleaned_mhc.csv')\n",
    "\n",
    "# Chuẩn bị dữ liệu\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    corpus['text'],\n",
    "    corpus['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=3500)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "n_components = 100\n",
    "\n",
    "lsa = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = lsa.transform(X_test_tfidf)\n",
    "\n",
    "print(f\"TF-IDF - Train shape: {X_train_tfidf.shape}, Test Shape: {X_test_tfidf.shape}\")\n",
    "print(f\"LSA - Train shape: {X_train_lsa.shape}, Test Shape: {X_test_lsa.shape}\\n\")\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Running on GPU.\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Capability: {torch.cuda.get_device_capability(0)}\")\n",
    "    print(f\"Total GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n",
    "    \n",
    "print(f\"CPU: {torch.get_num_threads()} threads available\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b4d2db-fd1d-42b9-949f-ca53b9466d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.4621\n",
      "Epoch [2/50], Loss: 0.2765\n",
      "Epoch [3/50], Loss: 0.2185\n",
      "Epoch [4/50], Loss: 0.1790\n",
      "Epoch [5/50], Loss: 0.1503\n",
      "Epoch [6/50], Loss: 0.1257\n",
      "Epoch [7/50], Loss: 0.1197\n",
      "Epoch [8/50], Loss: 0.1108\n",
      "Epoch [9/50], Loss: 0.1014\n",
      "Epoch [10/50], Loss: 0.0977\n",
      "Epoch [11/50], Loss: 0.0926\n",
      "Epoch [12/50], Loss: 0.0892\n",
      "Epoch [13/50], Loss: 0.0913\n",
      "Epoch [14/50], Loss: 0.0940\n",
      "Epoch [15/50], Loss: 0.0857\n",
      "Epoch [16/50], Loss: 0.0786\n",
      "Epoch [17/50], Loss: 0.0691\n",
      "Epoch [18/50], Loss: 0.0755\n",
      "Epoch [19/50], Loss: 0.0696\n",
      "Epoch [20/50], Loss: 0.0712\n",
      "Epoch [21/50], Loss: 0.0684\n",
      "Epoch [22/50], Loss: 0.0586\n",
      "Epoch [23/50], Loss: 0.0588\n",
      "Epoch [24/50], Loss: 0.0542\n",
      "Epoch [25/50], Loss: 0.0633\n",
      "Epoch [26/50], Loss: 0.0600\n",
      "Epoch [27/50], Loss: 0.0595\n",
      "Epoch [28/50], Loss: 0.0562\n",
      "Epoch [29/50], Loss: 0.0527\n",
      "Epoch [30/50], Loss: 0.0540\n",
      "Epoch [31/50], Loss: 0.0497\n",
      "Epoch [32/50], Loss: 0.0467\n",
      "Epoch [33/50], Loss: 0.0442\n",
      "Epoch [34/50], Loss: 0.0498\n",
      "Epoch [35/50], Loss: 0.0480\n",
      "Epoch [36/50], Loss: 0.0418\n",
      "Epoch [37/50], Loss: 0.0489\n",
      "Epoch [38/50], Loss: 0.0407\n",
      "Epoch [39/50], Loss: 0.0385\n",
      "Epoch [40/50], Loss: 0.0350\n",
      "Epoch [41/50], Loss: 0.0466\n",
      "Epoch [42/50], Loss: 0.0338\n",
      "Epoch [43/50], Loss: 0.0309\n",
      "Epoch [44/50], Loss: 0.0379\n",
      "Epoch [45/50], Loss: 0.0337\n",
      "Epoch [46/50], Loss: 0.0357\n",
      "Epoch [47/50], Loss: 0.0365\n",
      "Epoch [48/50], Loss: 0.0300\n",
      "Epoch [49/50], Loss: 0.0320\n",
      "Epoch [50/50], Loss: 0.0343\n",
      "Epoch [1/50], Loss: 0.6414\n",
      "Epoch [2/50], Loss: 0.3900\n",
      "Epoch [3/50], Loss: 0.3173\n",
      "Epoch [4/50], Loss: 0.2970\n",
      "Epoch [5/50], Loss: 0.2854\n",
      "Epoch [6/50], Loss: 0.2836\n",
      "Epoch [7/50], Loss: 0.2760\n",
      "Epoch [8/50], Loss: 0.2702\n",
      "Epoch [9/50], Loss: 0.2687\n",
      "Epoch [10/50], Loss: 0.2677\n",
      "Epoch [11/50], Loss: 0.2605\n",
      "Epoch [12/50], Loss: 0.2631\n",
      "Epoch [13/50], Loss: 0.2566\n",
      "Epoch [14/50], Loss: 0.2573\n",
      "Epoch [15/50], Loss: 0.2512\n",
      "Epoch [16/50], Loss: 0.2500\n",
      "Epoch [17/50], Loss: 0.2461\n",
      "Epoch [18/50], Loss: 0.2438\n",
      "Epoch [19/50], Loss: 0.2448\n",
      "Epoch [20/50], Loss: 0.2420\n",
      "Epoch [21/50], Loss: 0.2415\n",
      "Epoch [22/50], Loss: 0.2380\n",
      "Epoch [23/50], Loss: 0.2357\n",
      "Epoch [24/50], Loss: 0.2390\n",
      "Epoch [25/50], Loss: 0.2403\n",
      "Epoch [26/50], Loss: 0.2375\n",
      "Epoch [27/50], Loss: 0.2322\n",
      "Epoch [28/50], Loss: 0.2359\n",
      "Epoch [29/50], Loss: 0.2273\n",
      "Epoch [30/50], Loss: 0.2312\n",
      "Epoch [31/50], Loss: 0.2274\n",
      "Epoch [32/50], Loss: 0.2308\n",
      "Epoch [33/50], Loss: 0.2271\n",
      "Epoch [34/50], Loss: 0.2243\n",
      "Epoch [35/50], Loss: 0.2231\n",
      "Epoch [36/50], Loss: 0.2238\n",
      "Epoch [37/50], Loss: 0.2227\n",
      "Epoch [38/50], Loss: 0.2194\n",
      "Epoch [39/50], Loss: 0.2199\n",
      "Epoch [40/50], Loss: 0.2201\n",
      "Epoch [41/50], Loss: 0.2232\n",
      "Epoch [42/50], Loss: 0.2151\n",
      "Epoch [43/50], Loss: 0.2156\n",
      "Epoch [44/50], Loss: 0.2196\n",
      "Epoch [45/50], Loss: 0.2134\n",
      "Epoch [46/50], Loss: 0.2193\n",
      "Epoch [47/50], Loss: 0.2161\n",
      "Epoch [48/50], Loss: 0.2173\n",
      "Epoch [49/50], Loss: 0.2108\n",
      "Epoch [50/50], Loss: 0.2086\n",
      "\n",
      "Results:\n",
      "        Model  Train Accuracy (no dropout)  Train Accuracy (with dropout)  \\\n",
      "0  MLP-TF-IDF                     0.997042                       0.507154   \n",
      "1     MLP-LSA                     0.943632                       0.500861   \n",
      "\n",
      "   Test Accuracy  Train F1 Score  Test F1 Score  Train Precision  \\\n",
      "0       0.917169        0.997277       0.925344         0.997228   \n",
      "1       0.912651        0.948226       0.921042         0.946170   \n",
      "\n",
      "   Test Precision  Train Recall  Test Recall  Fit Time (s)  Test Time (s)  \n",
      "0        0.914877      0.997326     0.936053     92.134437       0.482002  \n",
      "1        0.913228      0.950292     0.928992     46.565175       0.477535  \n",
      "\n",
      "Confusion Matrices:\n",
      "\n",
      "MLP-TF-IDF Train Confusion Matrix:\n",
      "[[ 8465    28]\n",
      " [   27 10072]]\n",
      "\n",
      "MLP-TF-IDF Test Confusion Matrix:\n",
      "[[1877  222]\n",
      " [ 163 2386]]\n",
      "\n",
      "MLP-LSA Train Confusion Matrix:\n",
      "[[7947  546]\n",
      " [ 502 9597]]\n",
      "\n",
      "MLP-LSA Test Confusion Matrix:\n",
      "[[1874  225]\n",
      " [ 181 2368]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the device (GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, architecture='tfidf', custom_layers=None):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Default architectures\n",
    "        architectures = {\n",
    "            'tfidf': {\n",
    "                'hidden_layers': [2048, 1024, 512, 256, 128, 64, 32, 16, 8, 4],\n",
    "                'dropout_rates': [0.5, 0.4, 0.3, 0.3, 0.3, 0.2, 0.2, 0.1, 0.1, 0.1]\n",
    "            },\n",
    "            'lsa': {\n",
    "                'hidden_layers': [64, 32, 32, 16, 16, 8, 8, 4],\n",
    "                'dropout_rates': [0.4, 0.3, 0.3, 0.3, 0.2, 0.1, 0.1]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Use custom layers if provided, otherwise use default architecture\n",
    "        if custom_layers:\n",
    "            hidden_layers = custom_layers['hidden_layers']\n",
    "            dropout_rates = custom_layers['dropout_rates']\n",
    "        else:\n",
    "            hidden_layers = architectures[architecture]['hidden_layers']\n",
    "            dropout_rates = architectures[architecture]['dropout_rates']\n",
    "        \n",
    "        # Build layers\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for i, (hidden_size, dropout_rate) in enumerate(zip(hidden_layers, dropout_rates)):\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_size, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def prepare_data(X_train, y_train, X_test, y_test, batch_size):\n",
    "    # Convert to dense if sparse\n",
    "    if hasattr(X_train, \"toarray\"):\n",
    "        X_train = X_train.toarray()\n",
    "    if hasattr(X_test, \"toarray\"):\n",
    "        X_test = X_test.toarray()\n",
    "        \n",
    "    # Move data to the selected device (GPU/CPU)\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "def train_evaluate_mlp(X_train, y_train, X_test, y_test, model_params):\n",
    "    # Unpack parameters\n",
    "    architecture = model_params.get('architecture', 'tfidf')\n",
    "    custom_layers = model_params.get('custom_layers', None)\n",
    "    learning_rate = model_params.get('learning_rate', 0.001)\n",
    "    batch_size = model_params.get('batch_size', 64)\n",
    "    epochs = model_params.get('epochs', 10)\n",
    "    model_name = model_params.get('model_name', f'MLP-{architecture.upper()}')\n",
    "    \n",
    "    # Prepare data\n",
    "    train_loader, test_loader = prepare_data(X_train, y_train, X_test, y_test, batch_size)\n",
    "    \n",
    "    # Initialize model, loss function, and optimizer\n",
    "    input_size = X_train.shape[1]\n",
    "    model = MLP(input_size=input_size, architecture=architecture, custom_layers=custom_layers).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    \n",
    "    # Training\n",
    "    start_fit = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Enable dropout during training\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss/len(train_loader):.4f}')\n",
    "            \n",
    "    fit_time = time.time() - start_fit\n",
    "\n",
    "    # Evaluation (with dropout disabled)\n",
    "    model.eval()\n",
    "    start_test = time.time()\n",
    "    with torch.no_grad():\n",
    "        # Training set evaluation (without dropout)\n",
    "        train_outputs = []\n",
    "        train_true = []\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            train_outputs.extend(torch.round(torch.sigmoid(outputs)).cpu().numpy())\n",
    "            train_true.extend(y_batch.cpu().numpy())\n",
    "        \n",
    "        # Test set evaluation\n",
    "        test_outputs = []\n",
    "        test_true = []\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            test_outputs.extend(torch.round(torch.sigmoid(outputs)).cpu().numpy())\n",
    "            test_true.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    test_time = time.time() - start_test\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Train Accuracy (with dropout)': accuracy_score(y_train, train_outputs),\n",
    "        'Train Accuracy (no dropout)': accuracy_score(train_true, train_outputs),\n",
    "        'Test Accuracy': accuracy_score(test_true, test_outputs),\n",
    "        'Train F1 Score': f1_score(train_true, train_outputs),\n",
    "        'Test F1 Score': f1_score(test_true, test_outputs),\n",
    "        'Train Precision': precision_score(train_true, train_outputs),\n",
    "        'Test Precision': precision_score(test_true, test_outputs),\n",
    "        'Train Recall': recall_score(train_true, train_outputs),\n",
    "        'Test Recall': recall_score(test_true, test_outputs),\n",
    "        'Fit Time (s)': fit_time,\n",
    "        'Test Time (s)': test_time,\n",
    "        'Train Confusion Matrix': confusion_matrix(train_true, train_outputs),\n",
    "        'Test Confusion Matrix': confusion_matrix(test_true, test_outputs)\n",
    "    }\n",
    "    \n",
    "    return metrics, model\n",
    "\n",
    "# Example usage:\n",
    "tfidf_params = {\n",
    "    'architecture': 'tfidf',\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 50,\n",
    "    'model_name': 'MLP-TF-IDF'\n",
    "}\n",
    "\n",
    "lsa_params = {\n",
    "    'architecture': 'lsa',\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 50,\n",
    "    'model_name': 'MLP-LSA'\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "metrics_list = []\n",
    "\n",
    "# Train TF-IDF model\n",
    "tfidf_metrics, tfidf_model = train_evaluate_mlp(X_train_tfidf, y_train, X_test_tfidf, y_test, tfidf_params)\n",
    "metrics_list.append(tfidf_metrics)\n",
    "\n",
    "# Train LSA model\n",
    "lsa_metrics, lsa_model = train_evaluate_mlp(X_train_lsa, y_train, X_test_lsa, y_test, lsa_params)\n",
    "metrics_list.append(lsa_metrics)\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(metrics_list)\n",
    "display_columns = ['Model', 'Train Accuracy (no dropout)', 'Train Accuracy (with dropout)', \n",
    "                  'Test Accuracy', 'Train F1 Score', 'Test F1 Score', \n",
    "                  'Train Precision', 'Test Precision', 'Train Recall', \n",
    "                  'Test Recall', 'Fit Time (s)', 'Test Time (s)']\n",
    "print(\"\\nResults:\")\n",
    "print(results_df[display_columns])\n",
    "\n",
    "# Print confusion matrices\n",
    "print(\"\\nConfusion Matrices:\")\n",
    "for metrics in metrics_list:\n",
    "    print(f\"\\n{metrics['Model']} Train Confusion Matrix:\")\n",
    "    print(metrics['Train Confusion Matrix'])\n",
    "    print(f\"\\n{metrics['Model']} Test Confusion Matrix:\")\n",
    "    print(metrics['Test Confusion Matrix'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU Test",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
