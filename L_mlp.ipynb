{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4479228b-5e89-44a6-ab50-b0ed724f6520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF - Train shape: (18592, 3500), Test Shape: (4648, 3500)\n",
      "LSA - Train shape: (18592, 100), Test Shape: (4648, 100)\n",
      "\n",
      "CUDA is available. Running on GPU.\n",
      "GPU Name: NVIDIA GeForce RTX 3060\n",
      "CUDA Version: 12.1\n",
      "GPU Capability: (8, 6)\n",
      "Total GPU Memory: 12.88 GB\n",
      "CPU: 6 threads available\n",
      "PyTorch Version: 2.5.1\n"
     ]
    }
   ],
   "source": [
    "# Nhập thư viện\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Đọc bộ dữ liệu\n",
    "corpus = pd.read_csv('data/cleaned_mhc.csv')\n",
    "\n",
    "# Chuẩn bị dữ liệu\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    corpus['text'],\n",
    "    corpus['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=3500)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "n_components = 100\n",
    "\n",
    "lsa = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = lsa.transform(X_test_tfidf)\n",
    "\n",
    "print(f\"TF-IDF - Train shape: {X_train_tfidf.shape}, Test Shape: {X_test_tfidf.shape}\")\n",
    "print(f\"LSA - Train shape: {X_train_lsa.shape}, Test Shape: {X_test_lsa.shape}\\n\")\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Running on GPU.\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Capability: {torch.cuda.get_device_capability(0)}\")\n",
    "    print(f\"Total GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")\n",
    "    \n",
    "print(f\"CPU: {torch.get_num_threads()} threads available\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64b4d2db-fd1d-42b9-949f-ca53b9466d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2521\n",
      "Epoch [2/10], Loss: 0.1588\n",
      "Epoch [3/10], Loss: 0.1070\n",
      "Epoch [4/10], Loss: 0.0681\n",
      "Epoch [5/10], Loss: 0.0510\n",
      "Epoch [6/10], Loss: 0.0474\n",
      "Epoch [7/10], Loss: 0.0415\n",
      "Epoch [8/10], Loss: 0.0335\n",
      "Epoch [9/10], Loss: 0.0262\n",
      "Epoch [10/10], Loss: 0.0283\n",
      "Epoch [1/10], Loss: 0.4406\n",
      "Epoch [2/10], Loss: 0.2994\n",
      "Epoch [3/10], Loss: 0.2794\n",
      "Epoch [4/10], Loss: 0.2682\n",
      "Epoch [5/10], Loss: 0.2666\n",
      "Epoch [6/10], Loss: 0.2663\n",
      "Epoch [7/10], Loss: 0.2571\n",
      "Epoch [8/10], Loss: 0.2539\n",
      "Epoch [9/10], Loss: 0.2515\n",
      "Epoch [10/10], Loss: 0.2496\n",
      "\n",
      "Results:\n",
      "        Model  Train Accuracy (no dropout)  Train Accuracy (with dropout)  \\\n",
      "0  MLP-TF-IDF                     0.999462                       0.506992   \n",
      "1     MLP-LSA                     0.920288                       0.504303   \n",
      "\n",
      "   Test Accuracy  Train F1 Score  Test F1 Score  Train Precision  \\\n",
      "0       0.916308        0.999505       0.924393         0.999703   \n",
      "1       0.909639        0.926713       0.918224         0.925615   \n",
      "\n",
      "   Test Precision  Train Recall  Test Recall  Fit Time (s)  Test Time (s)  \n",
      "0        0.916025      0.999307     0.932915      8.917685       0.295967  \n",
      "1        0.911480      0.927815     0.925069      6.917200       0.369357  \n",
      "\n",
      "Confusion Matrices:\n",
      "\n",
      "MLP-TF-IDF Train Confusion Matrix:\n",
      "[[ 8490     3]\n",
      " [    7 10092]]\n",
      "\n",
      "MLP-TF-IDF Test Confusion Matrix:\n",
      "[[1881  218]\n",
      " [ 171 2378]]\n",
      "\n",
      "MLP-LSA Train Confusion Matrix:\n",
      "[[7740  753]\n",
      " [ 729 9370]]\n",
      "\n",
      "MLP-LSA Test Confusion Matrix:\n",
      "[[1870  229]\n",
      " [ 191 2358]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the device (GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, architecture='tfidf', custom_layers=None):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        # Default architectures\n",
    "        architectures = {\n",
    "            'tfidf': {\n",
    "                'hidden_layers': [1024, 512, 256],\n",
    "                'dropout_rates': [0.5, 0.4, 0.3]\n",
    "            },\n",
    "            'lsa': {\n",
    "                'hidden_layers': [64, 32, 16, 8],\n",
    "                'dropout_rates': [0.4, 0.3, 0.3, 0.2]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Use custom layers if provided, otherwise use default architecture\n",
    "        if custom_layers:\n",
    "            hidden_layers = custom_layers['hidden_layers']\n",
    "            dropout_rates = custom_layers['dropout_rates']\n",
    "        else:\n",
    "            hidden_layers = architectures[architecture]['hidden_layers']\n",
    "            dropout_rates = architectures[architecture]['dropout_rates']\n",
    "        \n",
    "        # Build layers\n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for i, (hidden_size, dropout_rate) in enumerate(zip(hidden_layers, dropout_rates)):\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(prev_size, 1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def prepare_data(X_train, y_train, X_test, y_test, batch_size):\n",
    "    # Convert to dense if sparse\n",
    "    if hasattr(X_train, \"toarray\"):\n",
    "        X_train = X_train.toarray()\n",
    "    if hasattr(X_test, \"toarray\"):\n",
    "        X_test = X_test.toarray()\n",
    "        \n",
    "    # Move data to the selected device (GPU/CPU)\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "def train_evaluate_mlp(X_train, y_train, X_test, y_test, model_params):\n",
    "    # Unpack parameters\n",
    "    architecture = model_params.get('architecture', 'tfidf')\n",
    "    custom_layers = model_params.get('custom_layers', None)\n",
    "    learning_rate = model_params.get('learning_rate', 0.001)\n",
    "    batch_size = model_params.get('batch_size', 64)\n",
    "    epochs = model_params.get('epochs', 10)\n",
    "    model_name = model_params.get('model_name', f'MLP-{architecture.upper()}')\n",
    "    \n",
    "    # Prepare data\n",
    "    train_loader, test_loader = prepare_data(X_train, y_train, X_test, y_test, batch_size)\n",
    "    \n",
    "    # Initialize model, loss function, and optimizer\n",
    "    input_size = X_train.shape[1]\n",
    "    model = MLP(input_size=input_size, architecture=architecture, custom_layers=custom_layers).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    \n",
    "    # Training\n",
    "    start_fit = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Enable dropout during training\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss/len(train_loader):.4f}')\n",
    "            \n",
    "    fit_time = time.time() - start_fit\n",
    "\n",
    "    # Evaluation (with dropout disabled)\n",
    "    model.eval()\n",
    "    start_test = time.time()\n",
    "    with torch.no_grad():\n",
    "        # Training set evaluation (without dropout)\n",
    "        train_outputs = []\n",
    "        train_true = []\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            train_outputs.extend(torch.round(torch.sigmoid(outputs)).cpu().numpy())\n",
    "            train_true.extend(y_batch.cpu().numpy())\n",
    "        \n",
    "        # Test set evaluation\n",
    "        test_outputs = []\n",
    "        test_true = []\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            test_outputs.extend(torch.round(torch.sigmoid(outputs)).cpu().numpy())\n",
    "            test_true.extend(y_batch.cpu().numpy())\n",
    "    \n",
    "    test_time = time.time() - start_test\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'Model': model_name,\n",
    "        'Train Accuracy (with dropout)': accuracy_score(y_train, train_outputs),\n",
    "        'Train Accuracy (no dropout)': accuracy_score(train_true, train_outputs),\n",
    "        'Test Accuracy': accuracy_score(test_true, test_outputs),\n",
    "        'Train F1 Score': f1_score(train_true, train_outputs),\n",
    "        'Test F1 Score': f1_score(test_true, test_outputs),\n",
    "        'Train Precision': precision_score(train_true, train_outputs),\n",
    "        'Test Precision': precision_score(test_true, test_outputs),\n",
    "        'Train Recall': recall_score(train_true, train_outputs),\n",
    "        'Test Recall': recall_score(test_true, test_outputs),\n",
    "        'Fit Time (s)': fit_time,\n",
    "        'Test Time (s)': test_time,\n",
    "        'Train Confusion Matrix': confusion_matrix(train_true, train_outputs),\n",
    "        'Test Confusion Matrix': confusion_matrix(test_true, test_outputs)\n",
    "    }\n",
    "    \n",
    "    return metrics, model\n",
    "\n",
    "# Example usage:\n",
    "tfidf_params = {\n",
    "    'architecture': 'tfidf',\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 10,\n",
    "    'model_name': 'MLP-TF-IDF'\n",
    "}\n",
    "\n",
    "lsa_params = {\n",
    "    'architecture': 'lsa',\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 10,\n",
    "    'model_name': 'MLP-LSA'\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "metrics_list = []\n",
    "\n",
    "# Train TF-IDF model\n",
    "tfidf_metrics, tfidf_model = train_evaluate_mlp(X_train_tfidf, y_train, X_test_tfidf, y_test, tfidf_params)\n",
    "metrics_list.append(tfidf_metrics)\n",
    "\n",
    "# Train LSA model\n",
    "lsa_metrics, lsa_model = train_evaluate_mlp(X_train_lsa, y_train, X_test_lsa, y_test, lsa_params)\n",
    "metrics_list.append(lsa_metrics)\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(metrics_list)\n",
    "display_columns = ['Model', 'Train Accuracy (no dropout)', 'Train Accuracy (with dropout)', \n",
    "                  'Test Accuracy', 'Train F1 Score', 'Test F1 Score', \n",
    "                  'Train Precision', 'Test Precision', 'Train Recall', \n",
    "                  'Test Recall', 'Fit Time (s)', 'Test Time (s)']\n",
    "print(\"\\nResults:\")\n",
    "print(results_df[display_columns])\n",
    "\n",
    "# Print confusion matrices\n",
    "print(\"\\nConfusion Matrices:\")\n",
    "for metrics in metrics_list:\n",
    "    print(f\"\\n{metrics['Model']} Train Confusion Matrix:\")\n",
    "    print(metrics['Train Confusion Matrix'])\n",
    "    print(f\"\\n{metrics['Model']} Test Confusion Matrix:\")\n",
    "    print(metrics['Test Confusion Matrix'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU Test",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
