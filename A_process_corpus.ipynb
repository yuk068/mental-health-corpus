{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "300caef0-d578-4044-b597-f954c8ac866b",
   "metadata": {},
   "source": [
    "# Một số thông tin về bộ dữ liệu\n",
    "- Nguồn gốc của bộ dữ liệu: [Mental Health Corpus](https://www.kaggle.com/datasets/reihanenamdari/mental-health-corpus).\n",
    "\n",
    "### Mô tả bộ dữ liệu\n",
    "- Bộ dữ liệu là dạng Corpus (1 tập hợp các văn bản) trong ngôn ngữ Tiếng Anh.\n",
    "- Bộ Corpus gồm 2 cột `text` và `label` và 27977 hàng.\n",
    "- Cột `text` biểu thị cho những bình luận đến từ những người dùng trên nền tảng mạng xã hội.\n",
    "- Cột `label` gồm các giá trị 0 và 1, trong đó 1 biểu thị cho dấu hiệu của nội dung độc hại hoặc có liên kết với nguy cơ về các vấn đề tâm lý của người viết văn bản đó và 0 được coi là văn bản có thể bỏ qua trong mục đích trên.\n",
    "\n",
    "***Ghi chú:*** Bộ dữ liệu được chia sẻ trên nền tảng [Kaggle](https://www.kaggle.com/) bởi [Reihaneh Namdari](https://www.kaggle.com/reihanenamdari), một nhà phân tích dữ liệu và nhà tâm lý trị liệu. Do những lo ngại về quyền riêng tư, có rất ít thông tin về bộ dữ liệu ngoài những thông tin được cung cấp tại đây. Điều này đưa ra một vài lưu ý:\n",
    "\n",
    "- Chúng ta không biết dữ liệu đã được thu thập ở nền tảng cụ thể nào hay bằng cách nào.\n",
    "- Chúng ta không biết thêm được thông tin gì về cá nhân đã viết ra các bình luận.\n",
    "- Chúng ta không biết bộ dữ liệu đã được thu thập và tạo ra và khoảng thời gian nào.\n",
    "- Chúng ta chưa thể chắc bộ dữ liệu này có thực sự 100% là dữ liệu từ đời thật.\n",
    "- Chúng ta chưa thể chắc rằng bộ dữ liệu đã qua các bước xử lí nào và các bước đó đã được thực hiện trên toàn bộ bộ dữ liệu hay chưa.\n",
    "- Chúng ta chưa thể chắc nếu dữ liệu đã qua các bước chọn lọc, hay thậm chí là chứa dữ liệu mô phỏng khi chưa qua phân tích."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7e8ae7a5-f297-4afe-ab88-ffd697996067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhập thư viện\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Đọc bộ dữ liệu\n",
    "corpus = pd.read_csv('data/mental_health.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc9b346-8b42-4e18-9403-8d2e0356da73",
   "metadata": {},
   "source": [
    "# Tiền xử lý dữ liệu\n",
    "\n",
    "- Trước khi đi vào phân tích và dọn dữ liệu, ta thực hiện một số bước xử lý tiêu chuẩn khi tiếp cận 1 Corpus. Phần tiền xử lý dữ liệu sẽ đảm bảo những quy trình sau được thuận lợi và giảm bớt trở ngại và tài nguyên xử lý.\n",
    "- Mục đích của phần này là từ bộ Corpus gốc `./data/mental_health.csv`, ta thu được `./data/processed_mhc.csv` đã được xử lý sơ bộ (*mhc* viết tắt cho Mental Health Corpus).\n",
    "\n",
    "### Các bước tiền xử lý dữ liệu\n",
    "\n",
    "1. Loại bỏ dấu câu, các ký tự đặc biệt, chữ số.\n",
    "2. Chuyển mọi ký tự chữ cái in hoa về in thường (Lowercasing).\n",
    "3. Loại bỏ các đường liên kết phổ biển (Chứa *http*, *www*,...).\n",
    "4. Chuẩn hóa các ký tự như *Tab* hay nhiều dấu cách về 1 dấu cách.\n",
    "5. Loại bỏ các điểm trống hoặc chỉ có khoảng trắng.\n",
    "6. Loại bỏ các điểm trùng nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "529a81ff-cb2a-4c8f-9034-ba2ab3aa0f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows with numbers, punctuation, or special symbols: 0\n",
      "Unique characters removed: set()\n",
      "Number of rows affected: 0\n",
      "Number of rows with numbers, punctuation, or special symbols after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# Bước 1: Loại bỏ số, dấu câu, ký tự đặc biệt, chữ số\n",
    "def check_for_special(text):\n",
    "    return bool(re.search(r'[^a-zA-Z\\s]', text))\n",
    "\n",
    "rows_with_special = corpus[corpus['text'].apply(check_for_special)]\n",
    "print(f\"Total number of rows with numbers, punctuation, or special symbols: {rows_with_special.shape[0]}\")\n",
    "\n",
    "unique_chars_removed = set(re.findall(r'[^a-zA-Z\\s]', ' '.join(corpus['text'].values)))\n",
    "print(f\"Unique characters removed: {unique_chars_removed}\")\n",
    "\n",
    "corpus['text'] = corpus['text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "\n",
    "affected_rows = (rows_with_special.shape[0])  # since we are directly modifying the column\n",
    "print(f\"Number of rows affected: {affected_rows}\")\n",
    "\n",
    "remaining_special_rows = corpus[corpus['text'].apply(check_for_special)]\n",
    "print(f\"Number of rows with numbers, punctuation, or special symbols after cleaning: {remaining_special_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2cd998eb-d3e6-4256-a119-6598bea45d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows with uppercase letters before lowering case: 0\n",
      "Total number of rows with uppercase letters after lowering case: 0\n"
     ]
    }
   ],
   "source": [
    "# Bước 2: Chuyển mọi ký tự chữ cái in hoa về in thường\n",
    "def to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "rows_with_uppercase = corpus[corpus['text'].str.contains(r'[A-Z]', regex=True)]\n",
    "print(f\"Total number of rows with uppercase letters before lowering case: {rows_with_uppercase.shape[0]}\")\n",
    "\n",
    "corpus['text'] = corpus['text'].apply(to_lowercase)\n",
    "\n",
    "remaining_uppercase_rows = corpus[corpus['text'].str.contains(r'[A-Z]', regex=True)]\n",
    "print(f\"Total number of rows with uppercase letters after lowering case: {remaining_uppercase_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "71da9214-2693-48a6-aaf2-5c7657c1b743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows with links before removal: 0\n",
      "Total number of rows with links after removal: 0\n"
     ]
    }
   ],
   "source": [
    "# Bước 3: Loại bỏ các liên kết\n",
    "def contains_link(text):\n",
    "    return bool(re.search(r'http|www', text))\n",
    "\n",
    "rows_with_links_before = corpus[corpus['text'].apply(contains_link)]\n",
    "print(f\"Total number of rows with links before removal: {rows_with_links_before.shape[0]}\")\n",
    "\n",
    "corpus['text'] = corpus['text'].apply(lambda x: re.sub(r'http|www', '', x))\n",
    "\n",
    "rows_with_links_after = corpus[corpus['text'].apply(contains_link)]\n",
    "print(f\"Total number of rows with links after removal: {rows_with_links_after.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "770ea917-f323-4e83-b7c8-5a140b97cc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows with multiple spaces, tabs, or newlines: 0\n",
      "Number of rows with multiple spaces, tabs, or newlines after normalization: 0\n"
     ]
    }
   ],
   "source": [
    "# Bước 4: Chuẩn hóa khoảng trắng\n",
    "def normalize_whitespace(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "rows_with_extra_whitespace = corpus[corpus['text'].str.contains(r'\\s{2,}|\\t|\\n', regex=True)]\n",
    "print(f\"Total number of rows with multiple spaces, tabs, or newlines: {rows_with_extra_whitespace.shape[0]}\")\n",
    "\n",
    "corpus['text'] = corpus['text'].apply(normalize_whitespace)\n",
    "\n",
    "remaining_whitespace_rows = corpus[corpus['text'].str.contains(r'\\s{2,}|\\t|\\n', regex=True)]\n",
    "print(f\"Number of rows with multiple spaces, tabs, or newlines after normalization: {remaining_whitespace_rows.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "547446f1-489c-4f56-9331-515c8fb939b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows before removing empty or whitespace-only rows: 27969\n",
      "Total rows after removing empty or whitespace-only rows: 27969\n",
      "Total rows removed: 0\n"
     ]
    }
   ],
   "source": [
    "# Bước 5: Loại bỏ các điểm trống hoặc chỉ có khoảng trắng\n",
    "total_rows_before = corpus.shape[0]\n",
    "print(f\"Total rows before removing empty or whitespace-only rows: {total_rows_before}\")\n",
    "\n",
    "corpus = corpus[corpus['text'].str.strip().astype(bool)]\n",
    "\n",
    "total_rows_after = corpus.shape[0]\n",
    "print(f\"Total rows after removing empty or whitespace-only rows: {total_rows_after}\")\n",
    "\n",
    "rows_removed = total_rows_before - total_rows_after\n",
    "print(f\"Total rows removed: {rows_removed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d2d9adc5-fca9-4a3c-8c9d-3b4aaf19b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows before removing duplicates: 27969\n",
      "Indices of duplicate rows:\n",
      "[]\n",
      "\n",
      "Content of duplicate rows:\n",
      "Empty DataFrame\n",
      "Columns: [text, label]\n",
      "Index: []\n",
      "\n",
      "Total rows after removing duplicates: 27969\n",
      "Number of rows removed: 0\n",
      "Number of duplicate rows after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# Bước 6: Loại bỏ các điểm trùng nhau\n",
    "before_drop_dupes = corpus.shape[0]\n",
    "print(f\"Total rows before removing duplicates: {before_drop_dupes}\")\n",
    "\n",
    "duplicates = corpus[corpus.duplicated(subset=['text'], keep=False)]\n",
    "\n",
    "print(\"Indices of duplicate rows:\")\n",
    "print(duplicates.index.tolist())\n",
    "print(\"\\nContent of duplicate rows:\")\n",
    "print(duplicates.head(len(corpus.duplicated(subset=['text'], keep=False))))\n",
    "\n",
    "corpus = corpus.drop_duplicates(subset=['text'], keep='first')\n",
    "\n",
    "print(f\"\\nTotal rows after removing duplicates: {corpus.shape[0]}\")\n",
    "\n",
    "rows_removed = before_drop_dupes - corpus.shape[0]\n",
    "print(f\"Number of rows removed: {rows_removed}\")\n",
    "\n",
    "remaining_duplicates = corpus.duplicated(subset=['text']).sum()\n",
    "print(f\"Number of duplicate rows after cleaning: {remaining_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a47d87e3-ab60-4a56-97ed-09747b2adf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu lại `data/processed_mhc.csv`\n",
    "corpus.to_csv('data/processed_mhc.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
