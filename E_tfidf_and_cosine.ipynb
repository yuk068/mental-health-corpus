{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d99001d-f7a8-4e4d-b1e4-5c13ecc6a537",
   "metadata": {},
   "source": [
    "# Trích xuất đặc trưng với TF-IDF\n",
    "\n",
    "- Với bộ Corpus đã dọn `./data/cleaned_mhc.csv`, ta sử dụng phương pháp TF-IDF để trích xuất đặc trưng từ dữ liệu văn bản.\n",
    "\n",
    "### Các bước thực hiện trích xuất đặc trưng từ TF-IDF và phân tích ma trận TF-IDF\n",
    "- Thực hiện vector hóa các văn bản sử dụng `TfidfVectorizer` từ Sci-kit Learn, ta sẽ chọn tham số `max_features` phù hợp.\n",
    "- Sau khi xác định được `max_features`, ta sẽ khảo sát về bản chất của ma trận TF-IDF thu được.\n",
    "- Thực hiện phân tích về đồ tương đồng của các vector văn bản và vector token sử dụng Cosine Similarity.\n",
    "\n",
    "### Công thức trọng số\n",
    "Trọng số TF-IDF của  1 token $ i $ trong văn bản $ j $ được cho bởi công thức:\n",
    "\n",
    "$$ w_{i, j} = tf_{i, j} \\times \\left( \\log \\left( \\frac{N + 1}{df_i + 1} \\right) + 1 \\right) $$\n",
    "\n",
    "Trong đó:\n",
    "- $ N $ là tổng số văn bản trong Corpus.\n",
    "- $ tf_{i, j}  $ là tần suất xuất hiện của token $ i $ trong văn bản $ j $.\n",
    "- $ df_i $ là tần xuất có mặt của token $ i $ trong cả Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8bd8947-6e71-4738-b53b-d13ba4efb8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhập thư viện\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Đọc bộ dữ liệu\n",
    "corpus = pd.read_csv('data/cleaned_mhc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09aecac-8fd1-4c84-9741-18cb3df05997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of corpus: (23240, 2)\n",
      "Shape of tfidf_matrix_100: (23240, 100)\n",
      "Shape of tfidf_matrix_200: (23240, 200)\n",
      "Shape of tfidf_matrix_500: (23240, 500)\n",
      "Shape of tfidf_matrix_1000: (23240, 1000)\n",
      "Shape of tfidf_matrix_2000: (23240, 2000)\n",
      "Shape of tfidf_matrix_3000: (23240, 3000)\n",
      "Shape of tfidf_matrix_3500: (23240, 3500)\n",
      "Shape of tfidf_matrix_4500: (23240, 4500)\n",
      "Shape of tfidf_matrix_6000: (23240, 6000)\n"
     ]
    }
   ],
   "source": [
    "raw_shape = corpus.shape\n",
    "print(f\"Original shape of corpus: {raw_shape}\")\n",
    "\n",
    "max_features_list = [100, 200, 500, 1000, 2000, 3000, 3500, 4500, 6000]\n",
    "tfidf_vectorizers = [TfidfVectorizer(max_features=mf) for mf in max_features_list]\n",
    "\n",
    "tfidf_matrices = {\n",
    "    f\"tfidf_matrix_{max_features}\": vectorizer.fit_transform(corpus['text'])\n",
    "    for max_features, vectorizer in zip(max_features_list, tfidf_vectorizers)\n",
    "}\n",
    "\n",
    "for name, matrix in tfidf_matrices.items():\n",
    "    print(f\"Shape of {name}: {matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364da90b-4eb7-41ab-95c4-3ced95fa62e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_matrix_100 tfidf_matrix_200 tfidf_matrix_500 tfidf_matrix_1000 tfidf_matrix_2000 tfidf_matrix_3000 tfidf_matrix_3500 tfidf_matrix_4500 tfidf_matrix_6000\n",
      "            told          college            moved         treatment            income           maddock           maddock        clickclick           friesmy\n",
      "           tried       understand            water           current           officer             clack               haa               hoo           clinker\n",
      "           happy            least       eventually            abused           manager             brice             clack           maddock           scutter\n",
      "          around             used          control          homeless           appears          intended             ameno               haa        clickclick\n",
      "           month             kind              met           mention        threatened         narrative             brice               dor               haa\n",
      "          reason              yet          outside       opportunity              tone            merely              lick             ameno               hoo\n",
      "            many            seems             kept             cared          academic             naive           wealthy             clack           maddock\n",
      "           thats            money        happiness            loving            studio           columbo          delivers             brice               dor\n",
      "             job     relationship            worry         terrified           patient           village              alex              konf              gaur\n",
      "            come           matter           simply           treated        regardless          provides         hitchcock             sauce             ameno\n",
      "            long             call       medication            caused         advantage            united              anne            custer             clack\n",
      "         getting              kid             food      professional           decides           charlie             jason             maria             brice\n",
      "          person          talking           talked           missing           richard            allows        historical             bruno           axolotl\n",
      "             lot           making            fault             clear        atmosphere          customer        passionate               hee            bjvgze\n",
      "             try            found            spent           younger             comic             flesh         associate            sidney        rdogeprime\n",
      "           point            sorry            along           learned          divorced          inspired         attending              lucy              konf\n",
      "            said            leave            bring           bullied         coworkers         receiving        importance         carpenter           kolchak\n",
      "           since            guess         possible              wall          believed           absence          revealed        cinderella           monkees\n",
      "          parent             head            write          consider              paul            desert           grabbed            bourne            tenant\n",
      "            best        character           strong             value            george            settle             cling           stephen               fay\n"
     ]
    }
   ],
   "source": [
    "least_important_tokens = {}\n",
    "\n",
    "for i, (tfidf_matrix_name, tfidf_matrix) in enumerate(tfidf_matrices.items()):\n",
    "    tfidf_vectorizer = tfidf_vectorizers[i]\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    \n",
    "    mean_tfidf_scores = tfidf_matrix.mean(axis=0).A1\n",
    "    \n",
    "    tfidf_df = pd.DataFrame({\n",
    "        'token': feature_names,\n",
    "        'mean_tfidf': mean_tfidf_scores\n",
    "    })\n",
    "    \n",
    "    least_important = tfidf_df.nsmallest(20, 'mean_tfidf')\n",
    "    least_important_tokens[tfidf_matrix_name] = least_important['token'].values\n",
    "\n",
    "least_important_df = pd.DataFrame(dict(least_important_tokens))\n",
    "print(least_important_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959b6c3-42ee-4704-9588-496012ce3ce9",
   "metadata": {},
   "source": [
    "### Quyết định giới hạn vốn từ vựng\n",
    "- Qua việc phân tích các ma trận TF-IDF với các `max_features` khác nhau, ta thấy rằng đuôi của những ma trận này, thường là những token \"ít quan trọng\" đối với dữ liệu.\n",
    "- Tuy nhiên, ta cần đánh đổi giữa độ rộng của vốn từ vựng và việc thu nhập lượng nhiễu nhỏ nhất có thể vào các đặc trưng do trong quá trình đánh giá, TF-IDF sẽ cho tất cả các token không có trong vốn từ vựng của nó trọng số bằng 0.\n",
    "- Ta thấy rằng với `max_features` bằng 3500 hay vốn từ vựng bằng 3500, TF-IDF vẫn có thể trích xuất các token có nghĩa mà có thể là ta không muốn bỏ qua, từ 4500 trở đi, các token được coi là \"ít quan trọng\" phần lớn có vẻ là các từ vô nghĩa hoặc tên riêng, vì vậy, ta sẽ chọn TF-IDF với `max_features` = 3500 làm thước đo tiêu chuẩn cho các quá trình đánh giá sau."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c461fd-7b64-427c-95a7-ac1cf6af31bc",
   "metadata": {},
   "source": [
    "### Công thức Cosine Similarity\n",
    "Với 2 vector $ u $ và $ v $, Cos của góc giữa chúng được gọi là Cosine Similarity:\n",
    "$ Sim_c(u, v) := \\cos(\\theta) = \\frac{u \\cdot v}{|| u || \\cdot || v ||}$\n",
    "\n",
    "Với 2 vector được chuẩn hóa $ || u || = 1 $ và  $ || v || = 1 $, Cosine Similarity giữa chúng đơn giản là tích vô hướng:\n",
    "$ \\cos(\\theta) = u \\cdot v $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5d2a03b-2dd2-4d06-a006-e4c01d42287f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF matrix: (23240, 3500)\n",
      "Doc. Index   Zeros      Non-Zero   Magnitude \n",
      "------------------------------------------\n",
      "11456        3473       27         1.0000    \n",
      "1288         3488       12         1.0000    \n",
      "5535         3489       11         1.0000    \n",
      "12657        3492       8          1.0000    \n",
      "8603         3482       18         1.0000    \n",
      "8828         3449       51         1.0000    \n",
      "16011        3490       10         1.0000    \n",
      "7779         3485       15         1.0000    \n",
      "8779         3466       34         1.0000    \n",
      "11941        3420       80         1.0000    \n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=3500)\n",
    "tfidf_matrix = tfidf.fit_transform(corpus['text'])\n",
    "\n",
    "print(f\"Shape of TF-IDF matrix: {tfidf_matrix.shape}\")\n",
    "\n",
    "np.random.seed(42)\n",
    "random_indices = np.random.choice(tfidf_matrix.shape[0], 10, replace=False)\n",
    "\n",
    "print(f\"{'Doc. Index':<12} {'Zeros':<10} {'Non-Zero':<10} {'Magnitude':<10}\")\n",
    "print(\"-\" * 42)\n",
    "for i in random_indices:\n",
    "    doc = tfidf_matrix[i]\n",
    "    zero_count = doc.shape[1] - doc.count_nonzero()\n",
    "    non_zero_count = doc.count_nonzero()\n",
    "    magnitude = np.sqrt(doc.multiply(doc).sum())\n",
    "    print(f\"{i:<12} {zero_count:<10} {non_zero_count:<10} {magnitude:<10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe9f57-291a-4ebc-8b47-83037ee133ca",
   "metadata": {},
   "source": [
    "### Dữ liệu ma trận thưa\n",
    "- Ta có thể thấy rằng bản chất của các ma trận TF-IDF là chúng rất lớn và thường rất thưa, như có thể quan sát ở trên.\n",
    "- Chúng ta sẽ cần sử dụng những phương pháp phù hợp hơn khi làm việc với dữ liệu thưa nói riêng và dữ liệu văn bản nói chung.\n",
    "- Ngoài ra, `TfidfVectorizer` mặc định sẽ chuẩn hóa các vector văn bản, khiến chúng có độ lớn bằng 1, điều này giúp giảm thiểu sự nhạy cảm của phương pháp đối với độ dài của văn bản khác nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52c23f2-c35c-4568-bddb-2ae8d6b5eeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document Index 15464 (Class 0):\n",
      "guess show dude love girl yes love much dude wanna make love girl sorry cant im ready yet dude ready girl abortion hour ago\n",
      "\n",
      "Similar Doc  Class  Similarity Text                                              \n",
      "--------------------------------------------------------------------------------\n",
      "19288        0      0.4928     anyone talk girl problem thats dude think know eve...\n",
      "11111        0      0.4265     normalize calling guy queen girl bro dude day got ...\n",
      "7077         0      0.4029     see one dude skirt ima make convention fucking tod...\n",
      "16470        0      0.3710     care im dude want love mean hard girl think guy wa...\n",
      "10582        0      0.3667     school picture taken look like female version dude...\n",
      "\n",
      "Document Index 16482 (Class 0):\n",
      "inspiring movie laughed cried felt love true give hope miracle happen great cast ellen samantha old actress showtime must see movie\n",
      "\n",
      "Similar Doc  Class  Similarity Text                                              \n",
      "--------------------------------------------------------------------------------\n",
      "20685        0      0.3833     movie watcher often say great movie must scene con...\n",
      "16203        0      0.3312     great movie even though people including great fri...\n",
      "3678         0      0.3293     movie modern day movie one rare epic film make wan...\n",
      "20621        0      0.3192     movie specially child think enjoy movie older movi...\n",
      "23167        0      0.3062     great cast great acting great music character movi...\n",
      "\n",
      "Document Index 1841 (Class 1):\n",
      "year living like far long fight thought every day ive tried everything im tired im sorry\n",
      "\n",
      "Similar Doc  Class  Similarity Text                                              \n",
      "--------------------------------------------------------------------------------\n",
      "23026        1      0.4397     im sorryim sorry disappointing mom dad know im str...\n",
      "9854         1      0.3753     dream cant wake know start thr past year life mayb...\n",
      "1753         1      0.3691     hour hopeim indecisive bastard first jan feb tonig...\n",
      "18460        1      0.3586     hollow feel hollow feel like everything happening ...\n",
      "263          1      0.3559     give upim tired pain hurt im tired failure im tire...\n",
      "\n",
      "Document Index 23176 (Class 1):\n",
      "wish think hate black gaming headset microphone noise cancellation music headphone new xbox one laptop tablet mobile phone wired headphone cause wish suck\n",
      "\n",
      "Similar Doc  Class  Similarity Text                                              \n",
      "--------------------------------------------------------------------------------\n",
      "18270        0      0.3613     mobile gaming console gaming bad bow console peasa...\n",
      "1713         0      0.2855     dad sat phone laptop fucking sat pound lookin brok...\n",
      "8827         1      0.2795     wish money wish could make toxic family jealous mi...\n",
      "12184        0      0.2564     lmfao younger brother owns two laptop none bit les...\n",
      "9848         1      0.2434     fcking done cant anymore rent room aunt month mean...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "corpus['token_count'] = corpus['text'].apply(lambda x: len(x.split()))\n",
    "filtered_corpus = corpus[(corpus['token_count'] >= 15) & (corpus['token_count'] <= 25)]\n",
    "\n",
    "np.random.seed(0)\n",
    "class_0_docs = filtered_corpus[filtered_corpus['label'] == 0].sample(2, random_state=0).index\n",
    "class_1_docs = filtered_corpus[filtered_corpus['label'] == 1].sample(2, random_state=0).index\n",
    "selected_docs = list(class_0_docs) + list(class_1_docs)\n",
    "\n",
    "cosine_sim_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "for doc_id in selected_docs:\n",
    "    full_text = corpus.loc[doc_id, 'text']\n",
    "    print(f\"\\nDocument Index {doc_id} (Class {corpus.loc[doc_id, 'label']}):\\n{full_text}\\n\")\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim_matrix[doc_id]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:6]\n",
    "    \n",
    "    print(f\"{'Similar Doc':<12} {'Class':<6} {'Similarity':<10} {'Text':<50}\")\n",
    "    print(\"-\" * 80)\n",
    "    for sim_doc_id, score in sim_scores:\n",
    "        sim_doc_class = corpus.loc[sim_doc_id, 'label']\n",
    "        truncated_text = corpus.loc[sim_doc_id, 'text'][:50] + \"...\"\n",
    "        print(f\"{sim_doc_id:<12} {sim_doc_class:<6} {score:<10.4f} {truncated_text:<50}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13f79d5-e7b5-4768-bca8-9b866d71d956",
   "metadata": {},
   "source": [
    "### Sử dụng Cosine Similarity trên các Vector văn bản\n",
    "\n",
    "- Cosine Similarity đo góc giữa các vector, vì vậy với các vector văn bản, ta có thể hiểu rằng những kết quả này thể hiện độ \"tương đồng\" dựa trên \"độ quan trọng\" của các token xuất hiện trong văn bản.\n",
    "- Thậm chí ta thấy các các vector được cho là \"tương đồng\" với các văn bản được chọn đôi khi cũng có cùng lớp với nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70fbdfae-56f6-4197-b5ce-89fc9f9acc21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 7 terms with highest co-occurrence score for 'suicidal':\n",
      "Token: thought         Co-occurrence Score: 0.3086\n",
      "Token: know            Co-occurrence Score: 0.1934\n",
      "Token: im              Co-occurrence Score: 0.1856\n",
      "Token: ideation        Co-occurrence Score: 0.1846\n",
      "Token: feel            Co-occurrence Score: 0.1770\n",
      "Token: feeling         Co-occurrence Score: 0.1750\n",
      "Token: ive             Co-occurrence Score: 0.1694\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'depression':\n",
      "Token: anxiety         Co-occurrence Score: 0.2359\n",
      "Token: feel            Co-occurrence Score: 0.2037\n",
      "Token: year            Co-occurrence Score: 0.1991\n",
      "Token: life            Co-occurrence Score: 0.1908\n",
      "Token: im              Co-occurrence Score: 0.1825\n",
      "Token: ive             Co-occurrence Score: 0.1767\n",
      "Token: like            Co-occurrence Score: 0.1718\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'suicide':\n",
      "Token: cannot          Co-occurrence Score: 0.1240\n",
      "Token: hotline         Co-occurrence Score: 0.0874\n",
      "Token: commit          Co-occurrence Score: 0.0751\n",
      "Token: life            Co-occurrence Score: 0.0658\n",
      "Token: thought         Co-occurrence Score: 0.0654\n",
      "Token: ideation        Co-occurrence Score: 0.0654\n",
      "Token: know            Co-occurrence Score: 0.0651\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'kill':\n",
      "Token: want            Co-occurrence Score: 0.2724\n",
      "Token: im              Co-occurrence Score: 0.2333\n",
      "Token: going           Co-occurrence Score: 0.2116\n",
      "Token: life            Co-occurrence Score: 0.2023\n",
      "Token: know            Co-occurrence Score: 0.1876\n",
      "Token: cant            Co-occurrence Score: 0.1797\n",
      "Token: die             Co-occurrence Score: 0.1733\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'myself':\n",
      "Token: kill            Co-occurrence Score: 0.1716\n",
      "Token: want            Co-occurrence Score: 0.0752\n",
      "Token: feel            Co-occurrence Score: 0.0587\n",
      "Token: pit             Co-occurrence Score: 0.0536\n",
      "Token: badly           Co-occurrence Score: 0.0526\n",
      "Token: killing         Co-occurrence Score: 0.0514\n",
      "Token: hate            Co-occurrence Score: 0.0514\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'die':\n",
      "Token: want            Co-occurrence Score: 0.3732\n",
      "Token: im              Co-occurrence Score: 0.2223\n",
      "Token: life            Co-occurrence Score: 0.2144\n",
      "Token: live            Co-occurrence Score: 0.1964\n",
      "Token: know            Co-occurrence Score: 0.1939\n",
      "Token: cant            Co-occurrence Score: 0.1936\n",
      "Token: feel            Co-occurrence Score: 0.1836\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'pain':\n",
      "Token: want            Co-occurrence Score: 0.1990\n",
      "Token: life            Co-occurrence Score: 0.1848\n",
      "Token: im              Co-occurrence Score: 0.1732\n",
      "Token: cant            Co-occurrence Score: 0.1652\n",
      "Token: much            Co-occurrence Score: 0.1639\n",
      "Token: feel            Co-occurrence Score: 0.1596\n",
      "Token: end             Co-occurrence Score: 0.1593\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'sad':\n",
      "Token: feel            Co-occurrence Score: 0.1789\n",
      "Token: im              Co-occurrence Score: 0.1512\n",
      "Token: like            Co-occurrence Score: 0.1400\n",
      "Token: want            Co-occurrence Score: 0.1337\n",
      "Token: know            Co-occurrence Score: 0.1280\n",
      "Token: even            Co-occurrence Score: 0.1268\n",
      "Token: time            Co-occurrence Score: 0.1216\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'help':\n",
      "Token: need            Co-occurrence Score: 0.3198\n",
      "Token: please          Co-occurrence Score: 0.2666\n",
      "Token: know            Co-occurrence Score: 0.2607\n",
      "Token: im              Co-occurrence Score: 0.2446\n",
      "Token: get             Co-occurrence Score: 0.2267\n",
      "Token: want            Co-occurrence Score: 0.2233\n",
      "Token: cant            Co-occurrence Score: 0.2151\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'sorry':\n",
      "Token: im              Co-occurrence Score: 0.2300\n",
      "Token: know            Co-occurrence Score: 0.1450\n",
      "Token: like            Co-occurrence Score: 0.1172\n",
      "Token: ive             Co-occurrence Score: 0.1157\n",
      "Token: time            Co-occurrence Score: 0.1152\n",
      "Token: cant            Co-occurrence Score: 0.1139\n",
      "Token: friend          Co-occurrence Score: 0.1122\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'anxiety':\n",
      "Token: depression      Co-occurrence Score: 0.2359\n",
      "Token: social          Co-occurrence Score: 0.2052\n",
      "Token: im              Co-occurrence Score: 0.1766\n",
      "Token: ive             Co-occurrence Score: 0.1543\n",
      "Token: severe          Co-occurrence Score: 0.1538\n",
      "Token: cant            Co-occurrence Score: 0.1506\n",
      "Token: feel            Co-occurrence Score: 0.1379\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'therapy':\n",
      "Token: therapist       Co-occurrence Score: 0.1736\n",
      "Token: medication      Co-occurrence Score: 0.1677\n",
      "Token: session         Co-occurrence Score: 0.1653\n",
      "Token: feel            Co-occurrence Score: 0.1380\n",
      "Token: ive             Co-occurrence Score: 0.1339\n",
      "Token: tried           Co-occurrence Score: 0.1336\n",
      "Token: year            Co-occurrence Score: 0.1315\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'suffering':\n",
      "Token: life            Co-occurrence Score: 0.1341\n",
      "Token: end             Co-occurrence Score: 0.1217\n",
      "Token: suffer          Co-occurrence Score: 0.1212\n",
      "Token: pain            Co-occurrence Score: 0.1149\n",
      "Token: want            Co-occurrence Score: 0.1098\n",
      "Token: im              Co-occurrence Score: 0.0904\n",
      "Token: cant            Co-occurrence Score: 0.0874\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'pill':\n",
      "Token: sleeping        Co-occurrence Score: 0.1648\n",
      "Token: overdose        Co-occurrence Score: 0.1647\n",
      "Token: bottle          Co-occurrence Score: 0.1606\n",
      "Token: took            Co-occurrence Score: 0.1476\n",
      "Token: take            Co-occurrence Score: 0.1331\n",
      "Token: taking          Co-occurrence Score: 0.1237\n",
      "Token: im              Co-occurrence Score: 0.1073\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'redflag':\n",
      "Token: commit          Co-occurrence Score: 0.3385\n",
      "Token: im              Co-occurrence Score: 0.2066\n",
      "Token: know            Co-occurrence Score: 0.2046\n",
      "Token: life            Co-occurrence Score: 0.2010\n",
      "Token: thought         Co-occurrence Score: 0.1967\n",
      "Token: want            Co-occurrence Score: 0.1937\n",
      "Token: ive             Co-occurrence Score: 0.1890\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'movie':\n",
      "Token: character       Co-occurrence Score: 0.2840\n",
      "Token: great           Co-occurrence Score: 0.2632\n",
      "Token: scene           Co-occurrence Score: 0.2584\n",
      "Token: actor           Co-occurrence Score: 0.2575\n",
      "Token: film            Co-occurrence Score: 0.2391\n",
      "Token: story           Co-occurrence Score: 0.2390\n",
      "Token: plot            Co-occurrence Score: 0.2296\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'film':\n",
      "Token: scene           Co-occurrence Score: 0.3011\n",
      "Token: character       Co-occurrence Score: 0.2833\n",
      "Token: performance     Co-occurrence Score: 0.2784\n",
      "Token: director        Co-occurrence Score: 0.2461\n",
      "Token: movie           Co-occurrence Score: 0.2391\n",
      "Token: actor           Co-occurrence Score: 0.2372\n",
      "Token: story           Co-occurrence Score: 0.2292\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'character':\n",
      "Token: movie           Co-occurrence Score: 0.2840\n",
      "Token: film            Co-occurrence Score: 0.2833\n",
      "Token: plot            Co-occurrence Score: 0.2175\n",
      "Token: story           Co-occurrence Score: 0.2069\n",
      "Token: performance     Co-occurrence Score: 0.2008\n",
      "Token: actor           Co-occurrence Score: 0.1978\n",
      "Token: main            Co-occurrence Score: 0.1871\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'story':\n",
      "Token: movie           Co-occurrence Score: 0.2390\n",
      "Token: film            Co-occurrence Score: 0.2292\n",
      "Token: character       Co-occurrence Score: 0.2069\n",
      "Token: performance     Co-occurrence Score: 0.1531\n",
      "Token: great           Co-occurrence Score: 0.1509\n",
      "Token: one             Co-occurrence Score: 0.1461\n",
      "Token: well            Co-occurrence Score: 0.1460\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'actor':\n",
      "Token: movie           Co-occurrence Score: 0.2575\n",
      "Token: film            Co-occurrence Score: 0.2372\n",
      "Token: role            Co-occurrence Score: 0.2080\n",
      "Token: character       Co-occurrence Score: 0.1978\n",
      "Token: performance     Co-occurrence Score: 0.1972\n",
      "Token: great           Co-occurrence Score: 0.1825\n",
      "Token: director        Co-occurrence Score: 0.1674\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'performance':\n",
      "Token: film            Co-occurrence Score: 0.2784\n",
      "Token: role            Co-occurrence Score: 0.2058\n",
      "Token: character       Co-occurrence Score: 0.2008\n",
      "Token: movie           Co-occurrence Score: 0.1975\n",
      "Token: actor           Co-occurrence Score: 0.1972\n",
      "Token: scene           Co-occurrence Score: 0.1838\n",
      "Token: cast            Co-occurrence Score: 0.1580\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'show':\n",
      "Token: television      Co-occurrence Score: 0.1753\n",
      "Token: episode         Co-occurrence Score: 0.1542\n",
      "Token: character       Co-occurrence Score: 0.1485\n",
      "Token: series          Co-occurrence Score: 0.1324\n",
      "Token: watch           Co-occurrence Score: 0.1276\n",
      "Token: movie           Co-occurrence Score: 0.1219\n",
      "Token: one             Co-occurrence Score: 0.1144\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'plot':\n",
      "Token: movie           Co-occurrence Score: 0.2296\n",
      "Token: character       Co-occurrence Score: 0.2175\n",
      "Token: film            Co-occurrence Score: 0.2127\n",
      "Token: twist           Co-occurrence Score: 0.1539\n",
      "Token: scene           Co-occurrence Score: 0.1381\n",
      "Token: acting          Co-occurrence Score: 0.1247\n",
      "Token: actor           Co-occurrence Score: 0.1217\n",
      "\n",
      "Top 7 terms with highest co-occurrence score for 'acting':\n",
      "Token: film            Co-occurrence Score: 0.2173\n",
      "Token: movie           Co-occurrence Score: 0.2160\n",
      "Token: great           Co-occurrence Score: 0.1567\n",
      "Token: character       Co-occurrence Score: 0.1543\n",
      "Token: actor           Co-occurrence Score: 0.1437\n",
      "Token: excellent       Co-occurrence Score: 0.1400\n",
      "Token: superb          Co-occurrence Score: 0.1388\n"
     ]
    }
   ],
   "source": [
    "tokens = tfidf.get_feature_names_out()\n",
    "\n",
    "token_similarity_matrix = cosine_similarity(tfidf_matrix.T)\n",
    "\n",
    "token_sim_df = pd.DataFrame(token_similarity_matrix, index=tokens, columns=tokens)\n",
    "\n",
    "tokens_of_interest = ['suicidal', 'depression', 'suicide', 'kill', 'myself', 'die',\n",
    "                         'pain', 'sad', 'help', 'sorry', 'anxiety', 'therapy',\n",
    "                         'suffering', 'pill', 'redflag',\n",
    "                         'movie', 'film', 'character', 'story', 'actor', 'performance', 'show',\n",
    "                         'plot', 'acting']\n",
    "\n",
    "for token in tokens_of_interest:\n",
    "    if token in tokens:\n",
    "        print(f\"\\nTop 7 terms with highest co-occurrence score for '{token}':\")\n",
    "        co_occurrences = token_sim_df[token].sort_values(ascending=False)[1:8]\n",
    "        for term, score in co_occurrences.items():\n",
    "            print(f\"Token: {term:<15} Co-occurrence Score: {score:.4f}\")\n",
    "    else:\n",
    "        print(f\"\\nToken '{token}' not found in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c79ebf-2919-4080-b904-706136c77db8",
   "metadata": {},
   "source": [
    "### Sử dụng Cosine Similarity trên các Vector token\n",
    "\n",
    "- Với vector token, có sự khác biệt so với vector văn bản.\n",
    "- Do bản chất TF-IDF không hiểu được ngữ nghĩa sâu xa, nên những kết quả trên có thể hiểu là độ \"tương đồng dựa trên độ quan trọng trên cả Corpus\" của mỗi token.\n",
    "- Chính vì vậy, những vector token có góc gần nhau chưa chắc đã là đồng nghĩa hay giống nhau mà có thể đơn giản chỉ là thường xuất hiện cùng nhau.\n",
    "- Điều này đồng thời cho thấy hạn chế của phương pháp khi so với các kĩ thuật Word Embedding."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MHC",
   "language": "python",
   "name": "mhc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
