{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ecbe6bf-24d3-466c-b86b-5c8290a63a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF - Train shape: (18592, 3500), Test Shape: (4648, 3500)\n",
      "LSA - Train shape: (18592, 100), Test Shape: (4648, 100)\n"
     ]
    }
   ],
   "source": [
    "# Nhập thư viện\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Đọc bộ dữ liệu\n",
    "corpus = pd.read_csv('data/cleaned_mhc.csv')\n",
    "\n",
    "# Chuẩn bị dữ liệu\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    corpus['text'],\n",
    "    corpus['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=3500)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "n_components = 100\n",
    "\n",
    "lsa = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = lsa.transform(X_test_tfidf)\n",
    "\n",
    "print(f\"TF-IDF - Train shape: {X_train_tfidf.shape}, Test Shape: {X_test_tfidf.shape}\")\n",
    "print(f\"LSA - Train shape: {X_train_lsa.shape}, Test Shape: {X_test_lsa.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02d6fa3a-a23d-4c46-b77c-b5279831c685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model  Train Accuracy  Test Accuracy  F1 Score  Precision    Recall  \\\n",
      "0  TF-IDF        0.939221       0.922762  0.929539   0.930086  0.928992   \n",
      "1     LSA        0.910499       0.908133  0.915862   0.920032  0.911730   \n",
      "\n",
      "   Fit Time (s)  Test Time (s)            Confusion Matrix  \n",
      "0         0.045          0.002  [[1921, 178], [181, 2368]]  \n",
      "1         0.019          0.002  [[1897, 202], [225, 2324]]  \n",
      "\n",
      "Confusion Matrices:\n",
      "TF-IDF Confusion Matrix:\n",
      "[[1921  178]\n",
      " [ 181 2368]]\n",
      "LSA Confusion Matrix:\n",
      "[[1897  202]\n",
      " [ 225 2324]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "C = 0.1\n",
    "penalty='l2'\n",
    "max_iter=1000\n",
    "\n",
    "# log_reg_tfidf = LogisticRegression(penalty=penalty, C=C, random_state=42, max_iter=max_iter)\n",
    "# log_reg_lsa = LogisticRegression(penalty=penalty, C=C, random_state=42, max_iter=max_iter)\n",
    "\n",
    "log_reg_tfidf = LogisticRegression(random_state=42, max_iter=max_iter)\n",
    "log_reg_lsa = LogisticRegression(random_state=42, max_iter=max_iter)\n",
    "\n",
    "metrics = {\n",
    "    'Model': ['TF-IDF', 'LSA'],\n",
    "    'Train Accuracy': [],\n",
    "    'Test Accuracy': [],\n",
    "    'F1 Score': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'Fit Time (s)': [],\n",
    "    'Test Time (s)': [],\n",
    "    'Confusion Matrix': []\n",
    "}\n",
    "\n",
    "start_fit = time.time()\n",
    "log_reg_tfidf.fit(X_train_tfidf, y_train)\n",
    "fit_time = time.time() - start_fit\n",
    "\n",
    "start_test = time.time()\n",
    "y_train_pred = log_reg_tfidf.predict(X_train_tfidf)\n",
    "y_test_pred = log_reg_tfidf.predict(X_test_tfidf)\n",
    "test_time = time.time() - start_test\n",
    "\n",
    "metrics['Train Accuracy'].append(accuracy_score(y_train, y_train_pred))\n",
    "metrics['Test Accuracy'].append(accuracy_score(y_test, y_test_pred))\n",
    "metrics['F1 Score'].append(f1_score(y_test, y_test_pred))\n",
    "metrics['Precision'].append(precision_score(y_test, y_test_pred))\n",
    "metrics['Recall'].append(recall_score(y_test, y_test_pred))\n",
    "metrics['Fit Time (s)'].append(fit_time)\n",
    "metrics['Test Time (s)'].append(test_time)\n",
    "metrics['Confusion Matrix'].append(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "start_fit = time.time()\n",
    "log_reg_lsa.fit(X_train_lsa, y_train)\n",
    "fit_time = time.time() - start_fit\n",
    "\n",
    "start_test = time.time()\n",
    "y_train_pred = log_reg_lsa.predict(X_train_lsa)\n",
    "y_test_pred = log_reg_lsa.predict(X_test_lsa)\n",
    "test_time = time.time() - start_test\n",
    "\n",
    "metrics['Train Accuracy'].append(accuracy_score(y_train, y_train_pred))\n",
    "metrics['Test Accuracy'].append(accuracy_score(y_test, y_test_pred))\n",
    "metrics['F1 Score'].append(f1_score(y_test, y_test_pred))\n",
    "metrics['Precision'].append(precision_score(y_test, y_test_pred))\n",
    "metrics['Recall'].append(recall_score(y_test, y_test_pred))\n",
    "metrics['Fit Time (s)'].append(fit_time)\n",
    "metrics['Test Time (s)'].append(test_time)\n",
    "metrics['Confusion Matrix'].append(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(metrics)\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\nConfusion Matrices:\")\n",
    "print(f\"TF-IDF Confusion Matrix:\\n{metrics['Confusion Matrix'][0]}\")\n",
    "print(f\"LSA Confusion Matrix:\\n{metrics['Confusion Matrix'][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8f2c29-8997-4164-84d7-0d09f9a0c54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 40 coefficients for TF-IDF model:\n",
      "redflag: 8.2986\n",
      "kill: 7.5121\n",
      "film: -6.0625\n",
      "suicidal: 5.8278\n",
      "life: 5.7273\n",
      "die: 5.5285\n",
      "movie: -5.3161\n",
      "cannot: 4.5489\n",
      "anymore: 4.3494\n",
      "depression: 4.2671\n",
      "killing: 3.9049\n",
      "feel: 3.9035\n",
      "want: 3.8964\n",
      "pill: 3.5690\n",
      "end: 3.4158\n",
      "living: 3.3890\n",
      "depressed: 3.3631\n",
      "alive: 3.3393\n",
      "crush: -3.3278\n",
      "yall: -3.1375\n",
      "tried: 3.1137\n",
      "job: 3.0395\n",
      "alone: 2.9842\n",
      "live: 2.9030\n",
      "worse: 2.8354\n",
      "family: 2.8202\n",
      "tired: 2.8084\n",
      "pain: 2.7970\n",
      "character: -2.7529\n",
      "kinda: -2.7526\n",
      "thought: 2.7406\n",
      "guy: -2.7318\n",
      "death: 2.7156\n",
      "que: 2.6913\n",
      "point: 2.6599\n",
      "nothing: 2.6406\n",
      "cant: 2.5813\n",
      "hospital: 2.5623\n",
      "done: 2.5501\n",
      "everything: 2.5449\n",
      "\n",
      "Top 15 coefficients for LSA model:\n",
      "Topic 4: -16.3353\n",
      "Topic 0: 15.0369\n",
      "Topic 1: -14.6454\n",
      "Topic 2: -12.1817\n",
      "Topic 6: -9.0092\n",
      "Topic 12: 6.7771\n",
      "Topic 8: -5.9071\n",
      "Topic 46: 4.8471\n",
      "Topic 25: -4.3797\n",
      "Topic 22: -4.0493\n",
      "Topic 43: -3.5501\n",
      "Topic 20: 3.2172\n",
      "Topic 64: 3.1986\n",
      "Topic 21: -3.0168\n",
      "Topic 41: -2.8932\n"
     ]
    }
   ],
   "source": [
    "feature_names_tfidf = tfidf.get_feature_names_out()\n",
    "\n",
    "k = 40\n",
    "\n",
    "coefficients_tfidf = log_reg_tfidf.coef_[0]\n",
    "top_k_tfidf_indices = np.argsort(np.abs(coefficients_tfidf))[-k:][::-1]\n",
    "top_k_tfidf_terms = [(feature_names_tfidf[i], coefficients_tfidf[i]) for i in top_k_tfidf_indices]\n",
    "\n",
    "print(f\"Top {k} coefficients for TF-IDF model:\")\n",
    "for term, coef in top_k_tfidf_terms:\n",
    "    print(f\"{term}: {coef:.4f}\")\n",
    "\n",
    "h = 15\n",
    "\n",
    "coefficients_lsa = log_reg_lsa.coef_[0]\n",
    "top_h_lsa_indices = np.argsort(np.abs(coefficients_lsa))[-h:][::-1]\n",
    "top_h_lsa_terms = [(f\"Topic {i}\", coefficients_lsa[i]) for i in top_h_lsa_indices]\n",
    "\n",
    "print(f\"\\nTop {h} coefficients for LSA model:\")\n",
    "for topic, coef in top_h_lsa_terms:\n",
    "    print(f\"{topic}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95072a3b-07e1-4b39-95f6-c0aa2d7d2864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg TFIDF Hyperparameters:\n",
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 5000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "LogReg LSA Hyperparameters:\n",
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 5000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(\"LogReg TFIDF Hyperparameters:\")\n",
    "print(log_reg_tfidf.get_params())\n",
    "\n",
    "print(\"\\nLogReg LSA Hyperparameters:\")\n",
    "print(log_reg_lsa.get_params())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MHC",
   "language": "python",
   "name": "mhc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
