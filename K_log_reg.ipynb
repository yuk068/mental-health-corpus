{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ecbe6bf-24d3-466c-b86b-5c8290a63a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF - Train shape: (18592, 3500), Test Shape: (4648, 3500)\n",
      "LSA - Train shape: (18592, 100), Test Shape: (4648, 100)\n"
     ]
    }
   ],
   "source": [
    "# Nhập thư viện\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Đọc bộ dữ liệu\n",
    "corpus = pd.read_csv('data/cleaned_mhc.csv')\n",
    "\n",
    "# Chuẩn bị dữ liệu\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    corpus['text'],\n",
    "    corpus['label'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=3500)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "n_components = 100\n",
    "\n",
    "lsa = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = lsa.transform(X_test_tfidf)\n",
    "\n",
    "print(f\"TF-IDF - Train shape: {X_train_tfidf.shape}, Test Shape: {X_test_tfidf.shape}\")\n",
    "print(f\"LSA - Train shape: {X_train_lsa.shape}, Test Shape: {X_test_lsa.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d6fa3a-a23d-4c46-b77c-b5279831c685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model  Train Accuracy  Test Accuracy  F1 Score  Precision    Recall  \\\n",
      "0  TF-IDF        0.960682       0.920611  0.927377   0.930490  0.924284   \n",
      "1     LSA        0.912328       0.910499  0.918046   0.922042  0.914084   \n",
      "\n",
      "   Fit Time (s)  Test Time (s)            Confusion Matrix  \n",
      "0      0.049736          0.001  [[1923, 176], [193, 2356]]  \n",
      "1      0.013000          0.002  [[1902, 197], [219, 2330]]  \n",
      "\n",
      "Confusion Matrices:\n",
      "TF-IDF Confusion Matrix:\n",
      "[[1923  176]\n",
      " [ 193 2356]]\n",
      "LSA Confusion Matrix:\n",
      "[[1902  197]\n",
      " [ 219 2330]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "C = 10\n",
    "penalty='l2'\n",
    "max_iter=5000\n",
    "\n",
    "log_reg_tfidf = LogisticRegression(penalty=penalty, C=C, random_state=42, max_iter=max_iter)\n",
    "log_reg_lsa = LogisticRegression(penalty=penalty, C=C, random_state=42, max_iter=max_iter)\n",
    "\n",
    "metrics = {\n",
    "    'Model': ['TF-IDF', 'LSA'],\n",
    "    'Train Accuracy': [],\n",
    "    'Test Accuracy': [],\n",
    "    'F1 Score': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'Fit Time (s)': [],\n",
    "    'Test Time (s)': [],\n",
    "    'Confusion Matrix': []\n",
    "}\n",
    "\n",
    "start_fit = time.time()\n",
    "log_reg_tfidf.fit(X_train_tfidf, y_train)\n",
    "fit_time = time.time() - start_fit\n",
    "\n",
    "start_test = time.time()\n",
    "y_train_pred = log_reg_tfidf.predict(X_train_tfidf)\n",
    "y_test_pred = log_reg_tfidf.predict(X_test_tfidf)\n",
    "test_time = time.time() - start_test\n",
    "\n",
    "metrics['Train Accuracy'].append(accuracy_score(y_train, y_train_pred))\n",
    "metrics['Test Accuracy'].append(accuracy_score(y_test, y_test_pred))\n",
    "metrics['F1 Score'].append(f1_score(y_test, y_test_pred))\n",
    "metrics['Precision'].append(precision_score(y_test, y_test_pred))\n",
    "metrics['Recall'].append(recall_score(y_test, y_test_pred))\n",
    "metrics['Fit Time (s)'].append(fit_time)\n",
    "metrics['Test Time (s)'].append(test_time)\n",
    "metrics['Confusion Matrix'].append(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "start_fit = time.time()\n",
    "log_reg_lsa.fit(X_train_lsa, y_train)\n",
    "fit_time = time.time() - start_fit\n",
    "\n",
    "start_test = time.time()\n",
    "y_train_pred = log_reg_lsa.predict(X_train_lsa)\n",
    "y_test_pred = log_reg_lsa.predict(X_test_lsa)\n",
    "test_time = time.time() - start_test\n",
    "\n",
    "metrics['Train Accuracy'].append(accuracy_score(y_train, y_train_pred))\n",
    "metrics['Test Accuracy'].append(accuracy_score(y_test, y_test_pred))\n",
    "metrics['F1 Score'].append(f1_score(y_test, y_test_pred))\n",
    "metrics['Precision'].append(precision_score(y_test, y_test_pred))\n",
    "metrics['Recall'].append(recall_score(y_test, y_test_pred))\n",
    "metrics['Fit Time (s)'].append(fit_time)\n",
    "metrics['Test Time (s)'].append(test_time)\n",
    "metrics['Confusion Matrix'].append(confusion_matrix(y_test, y_test_pred))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(metrics)\n",
    "print(results_df)\n",
    "\n",
    "print(\"\\nConfusion Matrices:\")\n",
    "print(f\"TF-IDF Confusion Matrix:\\n{metrics['Confusion Matrix'][0]}\")\n",
    "print(f\"LSA Confusion Matrix:\\n{metrics['Confusion Matrix'][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e8f2c29-8997-4164-84d7-0d09f9a0c54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 40 coefficients for TF-IDF model:\n",
      "redflag: 13.5501\n",
      "kill: 12.7129\n",
      "film: -12.4743\n",
      "suicidal: 10.0378\n",
      "killing: 8.7361\n",
      "movie: -8.6326\n",
      "die: 8.1371\n",
      "cannot: 7.7279\n",
      "pill: 7.2072\n",
      "life: 7.1283\n",
      "yall: -6.8403\n",
      "alive: 6.8078\n",
      "suicide: 6.7607\n",
      "depression: 6.5942\n",
      "minecraft: -6.5197\n",
      "tldr: -6.4792\n",
      "bruh: -6.4180\n",
      "crush: -6.3409\n",
      "medication: 6.2080\n",
      "rope: 6.2011\n",
      "covid: -6.1510\n",
      "anymore: 6.0792\n",
      "miserable: 6.0275\n",
      "kinda: -6.0032\n",
      "living: 5.9308\n",
      "gotta: -5.9059\n",
      "jump: 5.8981\n",
      "teenager: -5.7771\n",
      "myself: 5.5877\n",
      "debt: 5.5788\n",
      "ending: 5.5342\n",
      "falling: 5.5098\n",
      "depressed: 5.4928\n",
      "meme: -5.4091\n",
      "planning: 5.3554\n",
      "award: -5.3143\n",
      "scream: 5.1572\n",
      "worse: 5.1553\n",
      "que: 5.1341\n",
      "job: 5.0729\n",
      "\n",
      "Top 15 coefficients for LSA model:\n",
      "Topic 4: -22.6940\n",
      "Topic 1: -21.4265\n",
      "Topic 0: 18.1120\n",
      "Topic 2: -17.4899\n",
      "Topic 6: -12.3280\n",
      "Topic 12: 9.7850\n",
      "Topic 46: 8.9137\n",
      "Topic 8: -8.2117\n",
      "Topic 25: -6.7750\n",
      "Topic 22: -6.7008\n",
      "Topic 43: -6.4024\n",
      "Topic 20: 5.3073\n",
      "Topic 64: 5.0967\n",
      "Topic 41: -5.0431\n",
      "Topic 71: 4.6989\n"
     ]
    }
   ],
   "source": [
    "feature_names_tfidf = tfidf.get_feature_names_out()\n",
    "\n",
    "k = 40\n",
    "\n",
    "coefficients_tfidf = log_reg_tfidf.coef_[0]\n",
    "top_k_tfidf_indices = np.argsort(np.abs(coefficients_tfidf))[-k:][::-1]\n",
    "top_k_tfidf_terms = [(feature_names_tfidf[i], coefficients_tfidf[i]) for i in top_k_tfidf_indices]\n",
    "\n",
    "print(f\"Top {k} coefficients for TF-IDF model:\")\n",
    "for term, coef in top_k_tfidf_terms:\n",
    "    print(f\"{term}: {coef:.4f}\")\n",
    "\n",
    "h = 15\n",
    "\n",
    "coefficients_lsa = log_reg_lsa.coef_[0]\n",
    "top_h_lsa_indices = np.argsort(np.abs(coefficients_lsa))[-h:][::-1]\n",
    "top_h_lsa_terms = [(f\"Topic {i}\", coefficients_lsa[i]) for i in top_h_lsa_indices]\n",
    "\n",
    "print(f\"\\nTop {h} coefficients for LSA model:\")\n",
    "for topic, coef in top_h_lsa_terms:\n",
    "    print(f\"{topic}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95072a3b-07e1-4b39-95f6-c0aa2d7d2864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg TFIDF Hyperparameters:\n",
      "{'C': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "LogReg LSA Hyperparameters:\n",
      "{'C': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(\"LogReg TFIDF Hyperparameters:\")\n",
    "print(log_reg_tfidf.get_params())\n",
    "\n",
    "print(\"\\nLogReg LSA Hyperparameters:\")\n",
    "print(log_reg_lsa.get_params())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MHC",
   "language": "python",
   "name": "mhc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
