{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4abd9772-780e-47c8-b545-1fa6fd019e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Original Corpus (27977, 2)\n",
      "Shape of Cleaned Corpus (23240, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import matplotlib.cm as cm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "original_corpus = pd.read_csv('data/mental_health.csv')\n",
    "cleaned_corpus = pd.read_csv('data/cleaned_mhc.csv')\n",
    "\n",
    "print(\"Shape of Original Corpus\", original_corpus.shape)\n",
    "print(\"Shape of Cleaned Corpus\", cleaned_corpus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e56a71cb-b13b-4760-b222-bc39f50fa7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Tokens and Their TF-IDF Scores:\n",
      "     Token  TF-IDF Score\n",
      "1567    im   1464.219769\n",
      "1820  like    956.284352\n",
      "3363  want    931.238879\n",
      "1170  feel    822.814840\n",
      "1747  know    772.035204\n",
      "\n",
      "Last 30 Tokens and Their TF-IDF Scores:\n",
      "           Token  TF-IDF Score\n",
      "1540    humorous      5.268003\n",
      "100     allowing      5.261716\n",
      "2206  passionate      5.259987\n",
      "1252      foster      5.251934\n",
      "195    associate      5.240051\n",
      "211    attending      5.238587\n",
      "222    authority      5.182334\n",
      "1486  historical      5.134556\n",
      "2583    revealed      5.133668\n",
      "1238        ford      5.103191\n",
      "763       darker      5.095850\n",
      "1407     handled      5.094682\n",
      "1689       jason      5.091025\n",
      "2179   painfully      5.087388\n",
      "123         anne      4.991235\n",
      "2072     neglect      4.924122\n",
      "94          alex      4.920948\n",
      "1489   hitchcock      4.912864\n",
      "3338   virtually      4.852788\n",
      "2143       opera      4.764232\n",
      "747      cynical      4.688350\n",
      "3383     wealthy      4.652998\n",
      "805     delivers      4.640286\n",
      "1993  miniseries      4.500346\n",
      "1811        lick      4.477981\n",
      "378        brice      1.027152\n",
      "110        ameno      1.000000\n",
      "538        clack      0.999677\n",
      "1396         haa      0.929573\n",
      "1891     maddock      0.708841\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming cleaned_corpus is your DataFrame with a 'text' column\n",
    "tfidf = TfidfVectorizer(max_features=3500, stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(cleaned_corpus['text'])\n",
    "\n",
    "# Get the feature names (tokens)\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Convert the TF-IDF matrix to a dense format and create a DataFrame\n",
    "tfidf_dense = tfidf_matrix.todense()\n",
    "tfidf_df = pd.DataFrame(tfidf_dense, columns=feature_names)\n",
    "\n",
    "# Sum the scores for each token across all documents\n",
    "tfidf_scores = tfidf_df.sum(axis=0)\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "tokens_scores_df = pd.DataFrame(tfidf_scores, columns=['TF-IDF Score']).reset_index()\n",
    "tokens_scores_df.columns = ['Token', 'TF-IDF Score']\n",
    "\n",
    "# Sort by TF-IDF Score in descending order\n",
    "tokens_scores_df = tokens_scores_df.sort_values(by='TF-IDF Score', ascending=False)\n",
    "\n",
    "# Display the first 5 tokens\n",
    "print(\"First 5 Tokens and Their TF-IDF Scores:\")\n",
    "print(tokens_scores_df.head(5))\n",
    "\n",
    "# Display the last 30 tokens\n",
    "print(\"\\nLast 30 Tokens and Their TF-IDF Scores:\")\n",
    "print(tokens_scores_df.tail(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e205173-f958-442a-bbeb-3a612bb9407a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [0.0121003  0.00976051 0.00711625 0.00629515 0.00584499 0.00539468\n",
      " 0.00492761 0.0045552  0.00421667 0.00404742 0.00395734 0.00382405\n",
      " 0.00343066 0.00337167 0.00324869 0.00318699 0.00314025 0.0029621\n",
      " 0.00285895 0.00281437]\n",
      "Total explained variance: 0.09705385773838596\n",
      "\n",
      "Topic 1:\n",
      "im: 0.364\n",
      "want: 0.224\n",
      "like: 0.216\n",
      "feel: 0.212\n",
      "know: 0.184\n",
      "life: 0.175\n",
      "ive: 0.153\n",
      "dont: 0.139\n",
      "friend: 0.136\n",
      "time: 0.133\n",
      "\n",
      "Topic 2:\n",
      "movie: 0.505\n",
      "film: 0.444\n",
      "character: 0.136\n",
      "great: 0.131\n",
      "good: 0.130\n",
      "story: 0.127\n",
      "scene: 0.099\n",
      "time: 0.082\n",
      "seen: 0.078\n",
      "watch: 0.076\n",
      "\n",
      "Topic 3:\n",
      "im: 0.734\n",
      "movie: 0.146\n",
      "film: 0.122\n",
      "gonna: 0.102\n",
      "ive: 0.083\n",
      "going: 0.066\n",
      "tired: 0.054\n",
      "bored: 0.053\n",
      "sorry: 0.050\n",
      "ill: 0.048\n",
      "\n",
      "Topic 4:\n",
      "want: 0.503\n",
      "dont: 0.306\n",
      "movie: 0.246\n",
      "die: 0.212\n",
      "film: 0.211\n",
      "fucking: 0.160\n",
      "im: 0.146\n",
      "anymore: 0.102\n",
      "kill: 0.101\n",
      "tired: 0.093\n",
      "\n",
      "Topic 5:\n",
      "like: 0.426\n",
      "dont: 0.404\n",
      "feel: 0.315\n",
      "im: 0.130\n",
      "know: 0.123\n",
      "wanna: 0.119\n",
      "girl: 0.114\n",
      "talk: 0.108\n",
      "guy: 0.107\n",
      "movie: 0.104\n",
      "\n",
      "Topic 6:\n",
      "feel: 0.521\n",
      "like: 0.283\n",
      "im: 0.167\n",
      "life: 0.153\n",
      "tired: 0.079\n",
      "feeling: 0.078\n",
      "film: 0.064\n",
      "better: 0.062\n",
      "ive: 0.057\n",
      "movie: 0.054\n",
      "\n",
      "Topic 7:\n",
      "fucking: 0.612\n",
      "fuck: 0.339\n",
      "shit: 0.227\n",
      "hate: 0.218\n",
      "like: 0.179\n",
      "people: 0.142\n",
      "girl: 0.105\n",
      "guy: 0.098\n",
      "school: 0.082\n",
      "wanna: 0.066\n",
      "\n",
      "Topic 8:\n",
      "dont: 0.644\n",
      "know: 0.182\n",
      "life: 0.167\n",
      "ive: 0.120\n",
      "year: 0.108\n",
      "day: 0.077\n",
      "think: 0.064\n",
      "didnt: 0.052\n",
      "care: 0.049\n",
      "time: 0.047\n",
      "\n",
      "Topic 9:\n",
      "people: 0.418\n",
      "help: 0.383\n",
      "need: 0.308\n",
      "life: 0.171\n",
      "film: 0.127\n",
      "know: 0.117\n",
      "talk: 0.114\n",
      "post: 0.097\n",
      "fucking: 0.090\n",
      "care: 0.085\n",
      "\n",
      "Topic 10:\n",
      "film: 0.672\n",
      "want: 0.091\n",
      "girl: 0.061\n",
      "friend: 0.060\n",
      "school: 0.060\n",
      "feel: 0.041\n",
      "dont: 0.039\n",
      "like: 0.039\n",
      "play: 0.036\n",
      "performance: 0.035\n",
      "\n",
      "Topic 11:\n",
      "people: 0.497\n",
      "life: 0.223\n",
      "friend: 0.177\n",
      "think: 0.080\n",
      "make: 0.076\n",
      "girl: 0.072\n",
      "love: 0.070\n",
      "want: 0.065\n",
      "thing: 0.064\n",
      "person: 0.062\n",
      "\n",
      "Topic 12:\n",
      "friend: 0.531\n",
      "talk: 0.177\n",
      "fucking: 0.173\n",
      "movie: 0.149\n",
      "feel: 0.148\n",
      "ive: 0.134\n",
      "life: 0.128\n",
      "anymore: 0.125\n",
      "school: 0.114\n",
      "family: 0.111\n",
      "\n",
      "Topic 13:\n",
      "day: 0.504\n",
      "talk: 0.319\n",
      "wanna: 0.277\n",
      "life: 0.228\n",
      "friend: 0.193\n",
      "need: 0.164\n",
      "tired: 0.131\n",
      "bored: 0.126\n",
      "good: 0.099\n",
      "dont: 0.099\n",
      "\n",
      "Topic 14:\n",
      "school: 0.323\n",
      "need: 0.239\n",
      "year: 0.234\n",
      "life: 0.227\n",
      "help: 0.202\n",
      "like: 0.196\n",
      "dont: 0.153\n",
      "job: 0.139\n",
      "class: 0.115\n",
      "work: 0.109\n",
      "\n",
      "Topic 15:\n",
      "life: 0.367\n",
      "guy: 0.267\n",
      "girl: 0.264\n",
      "know: 0.248\n",
      "love: 0.180\n",
      "help: 0.150\n",
      "live: 0.085\n",
      "friend: 0.081\n",
      "like: 0.079\n",
      "going: 0.073\n",
      "\n",
      "Topic 16:\n",
      "ive: 0.414\n",
      "wanna: 0.341\n",
      "talk: 0.208\n",
      "girl: 0.192\n",
      "life: 0.140\n",
      "post: 0.136\n",
      "year: 0.134\n",
      "really: 0.129\n",
      "bored: 0.121\n",
      "guy: 0.120\n",
      "\n",
      "Topic 17:\n",
      "really: 0.426\n",
      "know: 0.254\n",
      "talk: 0.221\n",
      "kill: 0.211\n",
      "wanna: 0.192\n",
      "school: 0.167\n",
      "going: 0.167\n",
      "gonna: 0.121\n",
      "right: 0.110\n",
      "die: 0.106\n",
      "\n",
      "Topic 18:\n",
      "know: 0.544\n",
      "post: 0.240\n",
      "ive: 0.194\n",
      "day: 0.193\n",
      "school: 0.191\n",
      "hate: 0.161\n",
      "guy: 0.108\n",
      "feel: 0.104\n",
      "want: 0.102\n",
      "reddit: 0.090\n",
      "\n",
      "Topic 19:\n",
      "really: 0.466\n",
      "hate: 0.252\n",
      "day: 0.235\n",
      "girl: 0.200\n",
      "help: 0.184\n",
      "like: 0.165\n",
      "think: 0.146\n",
      "ive: 0.140\n",
      "life: 0.135\n",
      "school: 0.124\n",
      "\n",
      "Topic 20:\n",
      "hate: 0.476\n",
      "girl: 0.199\n",
      "talk: 0.191\n",
      "know: 0.180\n",
      "love: 0.138\n",
      "mom: 0.135\n",
      "need: 0.129\n",
      "wish: 0.128\n",
      "ive: 0.119\n",
      "tired: 0.113\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# 1. Initialize TF-IDF with specified parameters\n",
    "tfidf = TfidfVectorizer(max_features=2500, stop_words='english')\n",
    "\n",
    "# 2. Create TF-IDF matrix from cleaned corpus\n",
    "# Assuming the text column is 'text' - adjust if it's named differently\n",
    "tfidf_matrix = tfidf.fit_transform(cleaned_corpus['text'])\n",
    "\n",
    "# 3. Apply LSA (using TruncatedSVD)\n",
    "n_components = 20  # You can adjust this number\n",
    "lsa = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "lsa_matrix = lsa.fit_transform(tfidf_matrix)\n",
    "\n",
    "# 4. Analyze results\n",
    "# Get feature names (words)\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Print explained variance ratio\n",
    "print(\"Explained variance ratio:\", lsa.explained_variance_ratio_)\n",
    "print(\"Total explained variance:\", sum(lsa.explained_variance_ratio_))\n",
    "\n",
    "# 5. Extract and print top terms for each topic\n",
    "def print_topics(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[:-n_top_words-1:-1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "        \n",
    "        print(f\"\\nTopic {topic_idx + 1}:\")\n",
    "        for feature, weight in zip(top_features, weights):\n",
    "            print(f\"{feature}: {weight:.3f}\")\n",
    "\n",
    "# Print top 10 words per topic\n",
    "print_topics(lsa, feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd556da8-2c30-4f5e-ad3f-b4a5223fb194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Original Corpus:\n",
      "Accuracy: 0.2117\n",
      "Precision: 0.2046\n",
      "Recall: 0.2117\n",
      "F1 Score: 0.2072\n",
      "\n",
      "Metrics for Cleaned Corpus:\n",
      "Accuracy: 0.2123\n",
      "Precision: 0.2095\n",
      "Recall: 0.2123\n",
      "F1 Score: 0.2069\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the original and cleaned corpus\n",
    "original_corpus = pd.read_csv('data/mental_health.csv')  # Replace with actual path\n",
    "cleaned_corpus = pd.read_csv('data/cleaned_mhc.csv')\n",
    "\n",
    "# Define a function to run GMM and evaluate metrics\n",
    "def run_gmm_and_evaluate(corpus, corpus_name):\n",
    "    # 1. Prepare the data with TF-IDF\n",
    "    tfidf = TfidfVectorizer(max_features=2500, stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(corpus['text'])\n",
    "\n",
    "    # 2. Apply GMM clustering\n",
    "    n_clusters = 2  # Adjust as needed\n",
    "    gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "    corpus['cluster'] = gmm.fit_predict(tfidf_matrix.toarray())\n",
    "\n",
    "    # 3. Use cluster labels as predicted labels\n",
    "    # Assuming you have the true labels in the 'label' column\n",
    "    true_labels = corpus['label']\n",
    "\n",
    "    # 4. Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, corpus['cluster'])\n",
    "    precision = precision_score(true_labels, corpus['cluster'], average='weighted', zero_division=0)\n",
    "    recall = recall_score(true_labels, corpus['cluster'], average='weighted', zero_division=0)\n",
    "    f1 = f1_score(true_labels, corpus['cluster'], average='weighted', zero_division=0)\n",
    "\n",
    "    # 5. Print metrics\n",
    "    print(f\"Metrics for {corpus_name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\\n\")\n",
    "\n",
    "# Run GMM on the original corpus\n",
    "run_gmm_and_evaluate(original_corpus, \"Original Corpus\")\n",
    "\n",
    "# Run GMM on the cleaned corpus\n",
    "run_gmm_and_evaluate(cleaned_corpus, \"Cleaned Corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53115cb2-82ea-45da-a840-ca1c783424de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Original Corpus:\n",
      "Accuracy: 0.7883\n",
      "Precision: 0.7964\n",
      "Recall: 0.7883\n",
      "F1 Score: 0.7871\n",
      "\n",
      "Metrics for Cleaned Corpus:\n",
      "Accuracy: 0.7877\n",
      "Precision: 0.7887\n",
      "Recall: 0.7877\n",
      "F1 Score: 0.7863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the original and cleaned corpus\n",
    "original_corpus = pd.read_csv('data/mental_health.csv')  # Replace with actual path\n",
    "cleaned_corpus = pd.read_csv('data/cleaned_mhc.csv')\n",
    "\n",
    "# Define a function to run GMM and evaluate metrics\n",
    "def run_gmm_and_evaluate(corpus, corpus_name):\n",
    "    # 1. Prepare the data with TF-IDF\n",
    "    tfidf = TfidfVectorizer(max_features=2500, stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(corpus['text'])\n",
    "\n",
    "    # 2. Apply GMM clustering\n",
    "    n_clusters = 2  # Adjust as needed\n",
    "    gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "    corpus['cluster'] = gmm.fit_predict(tfidf_matrix.toarray())\n",
    "\n",
    "    # 3. Swap the cluster predictions\n",
    "    corpus['cluster'] = np.where(corpus['cluster'] == 0, 1, 0)  # Change 0 to 1 and 1 to 0\n",
    "\n",
    "    # 4. Use swapped cluster labels as predicted labels\n",
    "    true_labels = corpus['label']\n",
    "\n",
    "    # 5. Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, corpus['cluster'])\n",
    "    precision = precision_score(true_labels, corpus['cluster'], average='weighted', zero_division=0)\n",
    "    recall = recall_score(true_labels, corpus['cluster'], average='weighted', zero_division=0)\n",
    "    f1 = f1_score(true_labels, corpus['cluster'], average='weighted', zero_division=0)\n",
    "\n",
    "    # 6. Print metrics\n",
    "    print(f\"Metrics for {corpus_name}:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\\n\")\n",
    "\n",
    "# Run GMM on the original corpus\n",
    "run_gmm_and_evaluate(original_corpus, \"Original Corpus\")\n",
    "\n",
    "# Run GMM on the cleaned corpus\n",
    "run_gmm_and_evaluate(cleaned_corpus, \"Cleaned Corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3617d4-a520-45f3-b238-f1a1210693f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
