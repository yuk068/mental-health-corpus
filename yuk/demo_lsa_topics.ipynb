{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86354527-0d27-4088-bd04-054d39db4f96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "original_corpus = pd.read_csv('data/mental_health.csv')\n",
    "cleaned_corpus = pd.read_csv('data/cleaned_mhc.csv')\n",
    "\n",
    "print(\"Shape of Original Corpus\", original_corpus.shape)\n",
    "print(\"Shape of Cleaned Corpus\", cleaned_corpus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f90e5f-6ce1-4d48-8139-e000b7e1f256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "highlight_terms = ['suicidal', 'depression', 'suicide', 'kill', 'myself', 'die',\n",
    "                   'died', 'pain', 'sad', 'help', 'sorry', 'anxiety', 'therapy',\n",
    "                   'suffering', 'killing', 'pill',\n",
    "                   'movie', 'film', 'character', 'story', 'actor', 'performance', 'show',\n",
    "                   'plot', 'acting']\n",
    "\n",
    "n_topics = 3\n",
    "n_top_words = 200\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=3500)\n",
    "svd_model = TruncatedSVD(n_components=n_topics, random_state=42)\n",
    "\n",
    "def display_topics(model, feature_names, num_top_words, highlight_terms):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]\n",
    "        top_words = [word.upper() if word in highlight_terms else word for word in top_words]\n",
    "        print(f\"Topic {idx + 1}: {', '.join(top_words)} \\n\")\n",
    "\n",
    "X_original_tfidf = vectorizer.fit_transform(original_corpus['text'])\n",
    "svd_model.fit(X_original_tfidf)\n",
    "print(\"Top topics in Original Corpus:\")\n",
    "display_topics(svd_model, vectorizer.get_feature_names_out(), n_top_words, highlight_terms)\n",
    "\n",
    "X_cleaned_tfidf = vectorizer.fit_transform(cleaned_corpus['text'])\n",
    "svd_model.fit(X_cleaned_tfidf)\n",
    "print(\"\\nTop topics in Cleaned Corpus:\")\n",
    "display_topics(svd_model, vectorizer.get_feature_names_out(), n_top_words, highlight_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f1fa5-b5d6-4fe6-bfac-3bb314879d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "n_topics = 10\n",
    "n_top_words = 10\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=3500)\n",
    "svd_model = TruncatedSVD(n_components=n_topics, random_state=42)\n",
    "\n",
    "def display_topics(model, feature_names, num_top_words):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]\n",
    "        print(f\"Topic {idx + 1}: {', '.join(top_words)}\")\n",
    "\n",
    "X_original_tfidf = vectorizer.fit_transform(original_corpus['text'])\n",
    "svd_model.fit(X_original_tfidf)\n",
    "print(\"Top topics in Original Corpus:\")\n",
    "display_topics(svd_model, vectorizer.get_feature_names_out(), n_top_words)\n",
    "\n",
    "X_cleaned_tfidf = vectorizer.fit_transform(cleaned_corpus['text'])\n",
    "svd_model.fit(X_cleaned_tfidf)\n",
    "print(\"\\nTop topics in Cleaned Corpus:\")\n",
    "display_topics(svd_model, vectorizer.get_feature_names_out(), n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ebebe-3a54-4cbb-9f56-439dde5e857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def style_df_with_highlights(df, highlight_terms):\n",
    "    def highlight_words(val):\n",
    "        if isinstance(val, str) and val.upper() in [term.upper() for term in highlight_terms]:\n",
    "            return 'background-color: #800080'\n",
    "        return ''\n",
    "    \n",
    "    return df.style.applymap(highlight_words)\n",
    "\n",
    "def display_topics_tabular(model, feature_names, num_top_words, highlight_terms, words_per_row=15):\n",
    "    topic_dfs = []\n",
    "    \n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        # Get top words for the topic\n",
    "        top_words = [feature_names[i] for i in topic.argsort()[:-num_top_words - 1:-1]]\n",
    "        # Apply highlighting (uppercase)\n",
    "        top_words = [word.upper() if word in highlight_terms else word for word in top_words]\n",
    "        \n",
    "        # Calculate number of rows needed\n",
    "        num_rows = (len(top_words) + words_per_row - 1) // words_per_row\n",
    "        \n",
    "        # Create a 2D array of words, padding with empty strings if necessary\n",
    "        rows = []\n",
    "        for row in range(num_rows):\n",
    "            start_idx = row * words_per_row\n",
    "            end_idx = min(start_idx + words_per_row, len(top_words))\n",
    "            row_words = top_words[start_idx:end_idx]\n",
    "            # Pad row with empty strings if needed\n",
    "            row_words.extend([''] * (words_per_row - len(row_words)))\n",
    "            rows.append(row_words)\n",
    "        \n",
    "        # Create DataFrame for this topic\n",
    "        df = pd.DataFrame(\n",
    "            rows,\n",
    "            columns=[f'Token_{i+1}' for i in range(words_per_row)]\n",
    "        )\n",
    "        \n",
    "        # Add topic number as index\n",
    "        df.index = [f'Row_{i+1}' for i in range(len(df))]\n",
    "        \n",
    "        topic_dfs.append((idx + 1, df))\n",
    "\n",
    "    # Display each topic's DataFrame with styling\n",
    "    for topic_num, df in topic_dfs:\n",
    "        print(f\"\\nTopic {topic_num}\")\n",
    "        \n",
    "        # Apply styling and display\n",
    "        styled_df = style_df_with_highlights(df, highlight_terms)\n",
    "        \n",
    "        # Display the styled DataFrame\n",
    "        display(styled_df)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Example usage:\n",
    "highlight_terms = ['suicidal', 'depression', 'suicide', 'kill', 'myself', 'die',\n",
    "                   'died', 'pain', 'sad', 'help', 'sorry', 'anxiety', 'therapy',\n",
    "                   'suffering', 'killing', 'pill', 'depressed', 'death', 'cry', 'redflag', 'tired',\n",
    "                   'movie', 'film', 'character', 'story', 'actor', 'performance', 'show',\n",
    "                   'plot', 'acting', 'scene', 'watch', 'seen', 'funny', 'dvd', 'drama', \n",
    "\t\t   'dialouge', 'entertaining', 'hollywood', 'humor', 'star', 'horror', 'series',\n",
    "\t\t   'genre', 'production', 'cinema', 'effect', 'audience', 'picture', 'actress']\n",
    "\n",
    "n_topics = 3\n",
    "n_top_words = 195\n",
    "vectorizer = TfidfVectorizer(max_features=3500)\n",
    "svd_model = TruncatedSVD(n_components=n_topics, random_state=42)\n",
    "\n",
    "# For cleaned corpus\n",
    "X_cleaned_tfidf = vectorizer.fit_transform(cleaned_corpus['text'])\n",
    "svd_model.fit(X_cleaned_tfidf)\n",
    "print(\"\\nTop topics in Cleaned Corpus:\")\n",
    "display_topics_tabular(svd_model, vectorizer.get_feature_names_out(), n_top_words, highlight_terms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
