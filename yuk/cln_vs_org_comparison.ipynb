{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "246a8a1b-f1a8-4afc-8e5f-07e7305c6f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhập thư viện\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import matplotlib.cm as cm\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a60a249b-3ffb-4f0e-ad38-71b131e5e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Corpus:\n",
      "                                                 text  label\n",
      "0  dear american teens question dutch person hear...      0\n",
      "1  nothing look forward lifei dont many reasons k...      1\n",
      "2  music recommendations im looking expand playli...      0\n",
      "3  im done trying feel betterthe reason im still ...      1\n",
      "4  worried  year old girl subject domestic physic...      1\n",
      "5  hey rredflag sure right place post this goes  ...      1\n",
      "6  feel like someone needs hear tonight feeling r...      0\n",
      "7  deserve liveif died right noone would carei re...      1\n",
      "8  feels good ive set dateim killing friday nice ...      1\n",
      "9  live guiltok made stupid random choice  its ge...      1 \n",
      "\n",
      "Cleaned Corpus:\n",
      "                                                 text  label\n",
      "0  dear american teen question dutch person heard...      0\n",
      "1  nothing look forward life dont many reason kee...      1\n",
      "2  music recommendation im looking expand playlis...      0\n",
      "3  im done trying feel reason im still alive know...      1\n",
      "4  worried year old girl subject domestic going l...      1\n",
      "5  hey rredflag sure right place post go im curre...      1\n",
      "6  feel like someone need hear tonight feeling ri...      0\n",
      "7  deserve died right noone would care real frien...      1\n",
      "8  feel good ive set killing friday nice finally ...      1\n",
      "9  live made stupid random choice getting basical...      1\n",
      "\n",
      "Shape of original corpus: (27977, 2) and cleaned corpus: (27940, 2)\n",
      "Sample difference: 37\n"
     ]
    }
   ],
   "source": [
    "# Đọc 2 bộ dự liệu để so sánh\n",
    "org_corpus = pd.read_csv('data/mental_health.csv')\n",
    "\n",
    "cln_corpus = pd.read_csv('data/cleaned_mhc.csv')\n",
    "\n",
    "print(\"Original Corpus:\\n\", org_corpus.head(10), \"\\n\")\n",
    "print(\"Cleaned Corpus:\\n\", cln_corpus.head(10))\n",
    "\n",
    "print(f\"\\nShape of original corpus: {org_corpus.shape} and cleaned corpus: {cln_corpus.shape}\")\n",
    "print(f\"Sample difference: {org_corpus.shape[0] - cln_corpus.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c204232-ef5b-44fd-aa95-f54640e6bb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Corpus Stats:\n",
      "Class 1: Total tokens = 1337600, Unique tokens = 42130\n",
      "Class 0: Total tokens = 670013, Unique tokens = 49022\n",
      "Entire Corpus: Total tokens = 2007613, Unique tokens = 72649\n",
      "\n",
      "Cleaned Corpus Stats:\n",
      "Class 1: Total tokens = 1212239, Unique tokens = 12516\n",
      "Class 0: Total tokens = 584055, Unique tokens = 13883\n",
      "Entire Corpus: Total tokens = 1796294, Unique tokens = 14599\n"
     ]
    }
   ],
   "source": [
    "# So sánh unique tokens và total tokens\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "def token_stats(corpus, label_column='label'):\n",
    "    total_tokens_class_1 = corpus[corpus[label_column] == 1]['text'].apply(lambda x: len(tokenize(x))).sum()\n",
    "    total_tokens_class_0 = corpus[corpus[label_column] == 0]['text'].apply(lambda x: len(tokenize(x))).sum()\n",
    "    \n",
    "    unique_tokens_class_1 = set(token for text in corpus[corpus[label_column] == 1]['text'] for token in tokenize(text))\n",
    "    unique_tokens_class_0 = set(token for text in corpus[corpus[label_column] == 0]['text'] for token in tokenize(text))\n",
    "\n",
    "    total_tokens_entire = corpus['text'].apply(lambda x: len(tokenize(x))).sum()\n",
    "    unique_tokens_entire = set(token for text in corpus['text'] for token in tokenize(text))\n",
    "\n",
    "    return {\n",
    "        'total_tokens_class_1': total_tokens_class_1,\n",
    "        'total_tokens_class_0': total_tokens_class_0,\n",
    "        'unique_tokens_class_1': len(unique_tokens_class_1),\n",
    "        'unique_tokens_class_0': len(unique_tokens_class_0),\n",
    "        'total_tokens_entire': total_tokens_entire,\n",
    "        'unique_tokens_entire': len(unique_tokens_entire)\n",
    "    }\n",
    "\n",
    "original_stats = token_stats(org_corpus)\n",
    "\n",
    "cleaned_stats = token_stats(cln_corpus)\n",
    "\n",
    "print(\"Original Corpus Stats:\")\n",
    "print(f\"Class 1: Total tokens = {original_stats['total_tokens_class_1']}, Unique tokens = {original_stats['unique_tokens_class_1']}\")\n",
    "print(f\"Class 0: Total tokens = {original_stats['total_tokens_class_0']}, Unique tokens = {original_stats['unique_tokens_class_0']}\")\n",
    "print(f\"Entire Corpus: Total tokens = {original_stats['total_tokens_entire']}, Unique tokens = {original_stats['unique_tokens_entire']}\\n\")\n",
    "\n",
    "print(\"Cleaned Corpus Stats:\")\n",
    "print(f\"Class 1: Total tokens = {cleaned_stats['total_tokens_class_1']}, Unique tokens = {cleaned_stats['unique_tokens_class_1']}\")\n",
    "print(f\"Class 0: Total tokens = {cleaned_stats['total_tokens_class_0']}, Unique tokens = {cleaned_stats['unique_tokens_class_0']}\")\n",
    "print(f\"Entire Corpus: Total tokens = {cleaned_stats['total_tokens_entire']}, Unique tokens = {cleaned_stats['unique_tokens_entire']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f74ab355-8eb7-4193-a8f0-a6fdb9c2c4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Corpus Class Distribution:\n",
      "Class 0: Count = 14139, Percentage = 50.5%\n",
      "Class 1: Count = 13838, Percentage = 49.5%\n",
      "\n",
      "Cleaned Corpus Class Distribution:\n",
      "Class 0: Count = 14122, Percentage = 50.5%\n",
      "Class 1: Count = 13818, Percentage = 49.5%\n"
     ]
    }
   ],
   "source": [
    "# So sánh sự khác nhau của phân bổ lớp\n",
    "def class_distribution_with_percentage(corpus, label_column='label'):\n",
    "    class_counts = corpus[label_column].value_counts()\n",
    "    total_count = class_counts.sum()\n",
    "    percentages = (class_counts / total_count) * 100\n",
    "    return class_counts, percentages\n",
    "\n",
    "original_counts, original_percentages = class_distribution_with_percentage(org_corpus)\n",
    "\n",
    "cleaned_counts, cleaned_percentages = class_distribution_with_percentage(cln_corpus)\n",
    "\n",
    "print(\"Original Corpus Class Distribution:\")\n",
    "for label in original_counts.index:\n",
    "    print(f\"Class {label}: Count = {original_counts[label]}, Percentage = {original_percentages[label]:.1f}%\")\n",
    "\n",
    "print(\"\\nCleaned Corpus Class Distribution:\")\n",
    "for label in cleaned_counts.index:\n",
    "    print(f\"Class {label}: Count = {cleaned_counts[label]}, Percentage = {cleaned_percentages[label]:.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
