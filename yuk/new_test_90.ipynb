{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c46bcd7-b593-4db3-a491-9ad69e347aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9210150107219442\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92      2828\n",
      "           1       0.94      0.90      0.92      2768\n",
      "\n",
      "    accuracy                           0.92      5596\n",
      "   macro avg       0.92      0.92      0.92      5596\n",
      "weighted avg       0.92      0.92      0.92      5596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/mental_health.csv')\n",
    "\n",
    "# Shuffle the dataset to ensure randomness\n",
    "df = shuffle(df, random_state=42)\n",
    "\n",
    "# Extract the text and label columns\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets, ensuring class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Limit to 5000 features for efficiency\n",
    "\n",
    "# Fit the TF-IDF vectorizer on the training data only\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the fitted vectorizer\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model on the training data\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logreg.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7303a379-74fe-4a0d-84ed-25fda7d84afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.92012151536812\n",
      "\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92      2828\n",
      "           1       0.93      0.90      0.92      2768\n",
      "\n",
      "    accuracy                           0.92      5596\n",
      "   macro avg       0.92      0.92      0.92      5596\n",
      "weighted avg       0.92      0.92      0.92      5596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/mental_health.csv')\n",
    "\n",
    "# Shuffle the dataset to ensure randomness\n",
    "df = shuffle(df, random_state=42)\n",
    "\n",
    "# Extract the text and label columns\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Limit to 5000 features for efficiency\n",
    "\n",
    "# Transform the text data using TF-IDF\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "# Split the data into training (1%) and testing (99%) sets, ensuring class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, train_size=0.8, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"\\nSVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63493042-4d5f-4bee-b0b2-7f6dd61aa89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Accuracy with Word2Vec: 0.6861506245938335\n",
      "\n",
      "MLP Classification Report with Word2Vec:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.46      0.60     13998\n",
      "           1       0.62      0.92      0.74     13700\n",
      "\n",
      "    accuracy                           0.69     27698\n",
      "   macro avg       0.74      0.69      0.67     27698\n",
      "weighted avg       0.74      0.69      0.67     27698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/mental_health.csv')\n",
    "\n",
    "# Shuffle the dataset to ensure randomness\n",
    "df = shuffle(df, random_state=42)\n",
    "\n",
    "# Extract the text and label columns\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Preprocess the text: split each sentence into tokens (words)\n",
    "X_tokens = X.apply(lambda x: x.split())\n",
    "\n",
    "# Split the data into training (1%) and testing (99%) sets, ensuring class balance\n",
    "X_train_tokens, X_test_tokens, y_train, y_test = train_test_split(X_tokens, y, test_size=0.99, train_size=0.01, random_state=42, stratify=y)\n",
    "\n",
    "# Train a Word2Vec model using skip-gram (sg=1) only on the training data\n",
    "w2v_model = Word2Vec(sentences=X_train_tokens, vector_size=100, window=5, sg=1, min_count=1, workers=4, seed=42)\n",
    "\n",
    "# Create a function to get the average Word2Vec vectors for a given text\n",
    "def text_to_w2v(text_tokens, model):\n",
    "    word_vectors = [model.wv[word] for word in text_tokens if word in model.wv]\n",
    "    if len(word_vectors) == 0:  # In case no word in the sentence is in the model vocabulary\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Transform the training data into Word2Vec vectors\n",
    "X_train_w2v = np.array([text_to_w2v(text, w2v_model) for text in X_train_tokens])\n",
    "\n",
    "# Transform the test data into Word2Vec vectors (using the model trained on the training data)\n",
    "X_test_w2v = np.array([text_to_w2v(text, w2v_model) for text in X_test_tokens])\n",
    "\n",
    "# Initialize the MLP classifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=5000, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "mlp.fit(X_train_w2v, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_mlp = mlp.predict(X_test_w2v)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"MLP Accuracy with Word2Vec:\", accuracy_score(y_test, y_pred_mlp))\n",
    "print(\"\\nMLP Classification Report with Word2Vec:\\n\", classification_report(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a78ff1-4502-4f3f-ae18-bc863c72a58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8594844393096974\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86     13998\n",
      "           1       0.87      0.84      0.86     13700\n",
      "\n",
      "    accuracy                           0.86     27698\n",
      "   macro avg       0.86      0.86      0.86     27698\n",
      "weighted avg       0.86      0.86      0.86     27698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/mental_health.csv')\n",
    "\n",
    "# Shuffle the dataset to ensure randomness\n",
    "df = shuffle(df, random_state=42)\n",
    "\n",
    "# Extract the text and label columns\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training (80%) and testing (20%) sets, ensuring class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.99, train_size=0.01, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Limit to 5000 features for efficiency\n",
    "\n",
    "# Fit the TF-IDF vectorizer on the training data only\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the fitted vectorizer\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model on the training data\n",
    "logreg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = logreg.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e90af4-5b12-4dc3-9522-f3f3e733b7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
