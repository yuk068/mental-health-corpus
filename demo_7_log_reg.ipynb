{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55719649-fdaa-4562-a58d-83e534c761de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Original Corpus (27977, 2)\n",
      "Shape of Cleaned Corpus (23240, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "original_corpus = pd.read_csv('data/mental_health.csv')\n",
    "cleaned_corpus = pd.read_csv('data/cleaned_mhc.csv')\n",
    "\n",
    "print(\"Shape of Original Corpus\", original_corpus.shape)\n",
    "print(\"Shape of Cleaned Corpus\", cleaned_corpus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb4f9d0a-fb5a-4bea-9cff-7ae568666bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Original Corpus:\n",
      "Best F1 Score (C=1.0, penalty=l2): 0.9206\n",
      "Average Fit Time: 0.0918 s\n",
      "Average Test Time: 0.0005 s\n",
      "Confusion Matrix for Best Model:\n",
      " [[2598  204]\n",
      " [ 237 2557]]\n",
      "\n",
      "Results for Cleaned Corpus:\n",
      "Best F1 Score (C=1.0, penalty=l2): 0.9295\n",
      "Average Fit Time: 0.1501 s\n",
      "Average Test Time: 0.0004 s\n",
      "Confusion Matrix for Best Model:\n",
      " [[1921  178]\n",
      " [ 181 2368]]\n",
      "\n",
      "Coefficient Analysis for Original Corpus:\n",
      "\n",
      "Top 20 Most Influential Terms:\n",
      "Term                 Coefficient    \n",
      "-----------------------------------\n",
      "redflag              7.9595         \n",
      "kill                 7.4589         \n",
      "suicidal             5.5458         \n",
      "die                  5.5143         \n",
      "br                   -5.2353        \n",
      "life                 5.0054         \n",
      "film                 -4.8867        \n",
      "cannot               4.8758         \n",
      "movie                -4.7338        \n",
      "killing              4.2968         \n",
      "depression           4.2608         \n",
      "myself               4.1067         \n",
      "end                  3.9631         \n",
      "alive                3.9107         \n",
      "pills                3.9104         \n",
      "anymore              3.8730         \n",
      "crush                -3.7545        \n",
      "living               3.6858         \n",
      "feel                 3.4754         \n",
      "want                 3.4128         \n",
      "\n",
      "Top 20 Least Influential Terms:\n",
      "Term                 Coefficient    \n",
      "-----------------------------------\n",
      "parties              -0.0038        \n",
      "cross                -0.0034        \n",
      "concern              -0.0033        \n",
      "understood           -0.0027        \n",
      "claim                0.0026         \n",
      "july                 -0.0024        \n",
      "far                  -0.0017        \n",
      "busy                 -0.0017        \n",
      "regardless           -0.0015        \n",
      "struggles            -0.0015        \n",
      "bleed                -0.0015        \n",
      "brother              -0.0013        \n",
      "asking               -0.0013        \n",
      "sharing              -0.0011        \n",
      "brutal               -0.0009        \n",
      "wise                 0.0008         \n",
      "attraction           0.0008         \n",
      "march                0.0008         \n",
      "sold                 -0.0004        \n",
      "education            -0.0002        \n",
      "\n",
      "Coefficient Analysis for Cleaned Corpus:\n",
      "\n",
      "Top 20 Most Influential Terms:\n",
      "Term                 Coefficient    \n",
      "-----------------------------------\n",
      "redflag              8.2986         \n",
      "kill                 7.5121         \n",
      "film                 -6.0625        \n",
      "suicidal             5.8278         \n",
      "life                 5.7273         \n",
      "die                  5.5285         \n",
      "movie                -5.3161        \n",
      "cannot               4.5489         \n",
      "anymore              4.3494         \n",
      "depression           4.2671         \n",
      "killing              3.9049         \n",
      "feel                 3.9035         \n",
      "want                 3.8964         \n",
      "pill                 3.5690         \n",
      "end                  3.4158         \n",
      "living               3.3890         \n",
      "depressed            3.3631         \n",
      "alive                3.3393         \n",
      "crush                -3.3278        \n",
      "yall                 -3.1375        \n",
      "\n",
      "Top 20 Least Influential Terms:\n",
      "Term                 Coefficient    \n",
      "-----------------------------------\n",
      "marriage             0.0029         \n",
      "office               0.0028         \n",
      "following            0.0027         \n",
      "frustration          0.0026         \n",
      "rip                  -0.0025        \n",
      "business             0.0025         \n",
      "intimate             -0.0024        \n",
      "noticing             0.0024         \n",
      "gross                -0.0024        \n",
      "closed               0.0022         \n",
      "ten                  0.0022         \n",
      "thankful             -0.0019        \n",
      "street               0.0018         \n",
      "correctly            -0.0016        \n",
      "birth                0.0011         \n",
      "auto                 -0.0011        \n",
      "news                 -0.0011        \n",
      "customer             0.0009         \n",
      "sudden               0.0003         \n",
      "city                 -0.0002        \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Define hyperparameters to test\n",
    "C_values = [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "penalties = ['l1', 'l2']\n",
    "solvers = {\n",
    "    'l1': 'liblinear',\n",
    "    'l2': 'lbfgs'\n",
    "}\n",
    "\n",
    "def analyze_coefficients(model, vectorizer, dataset_name):\n",
    "    # Get feature names and coefficients\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    coefficients = model.coef_[0]  # For binary classification\n",
    "    \n",
    "    # Create a list of (term, coefficient) tuples\n",
    "    coef_pairs = list(zip(feature_names, coefficients))\n",
    "    \n",
    "    # Sort by absolute coefficient value\n",
    "    sorted_pairs = sorted(coef_pairs, key=lambda x: abs(x[1]), reverse=True)\n",
    "    \n",
    "    print(f\"\\nCoefficient Analysis for {dataset_name} Corpus:\")\n",
    "    print(\"\\nTop 20 Most Influential Terms:\")\n",
    "    print(\"{:<20} {:<15}\".format(\"Term\", \"Coefficient\"))\n",
    "    print(\"-\" * 35)\n",
    "    for term, coef in sorted_pairs[:20]:\n",
    "        print(\"{:<20} {:<15.4f}\".format(term, coef))\n",
    "        \n",
    "    print(\"\\nTop 20 Least Influential Terms:\")\n",
    "    print(\"{:<20} {:<15}\".format(\"Term\", \"Coefficient\"))\n",
    "    print(\"-\" * 35)\n",
    "    for term, coef in sorted_pairs[-20:]:\n",
    "        print(\"{:<20} {:<15.4f}\".format(term, coef))\n",
    "\n",
    "def run_logistic_regression(corpus, target, dataset_name):\n",
    "    best_f1 = 0\n",
    "    best_model = None\n",
    "    best_vectorizer = None\n",
    "    best_conf_matrix = None\n",
    "    best_params = None\n",
    "    total_fit_time = 0\n",
    "    total_test_time = 0\n",
    "    num_iterations = 0\n",
    "    \n",
    "    # Split data once\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        corpus, target, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Vectorize data\n",
    "    vectorizer = TfidfVectorizer(max_features=3500)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    \n",
    "    for penalty in penalties:\n",
    "        for C in C_values:\n",
    "            num_iterations += 1\n",
    "            \n",
    "            # Initialize model\n",
    "            lr = LogisticRegression(\n",
    "                C=C,\n",
    "                penalty=penalty,\n",
    "                solver=solvers[penalty],\n",
    "                max_iter=1000,\n",
    "                random_state=42\n",
    "            )\n",
    "            \n",
    "            # Fit model and time it\n",
    "            start_fit = time.perf_counter()\n",
    "            lr.fit(X_train_tfidf, y_train)\n",
    "            fit_time = time.perf_counter() - start_fit\n",
    "            total_fit_time += fit_time\n",
    "            \n",
    "            # Test model and time it\n",
    "            start_test = time.perf_counter()\n",
    "            y_test_pred = lr.predict(X_test_tfidf)\n",
    "            test_time = time.perf_counter() - start_test\n",
    "            total_test_time += test_time\n",
    "            \n",
    "            # Calculate F1 score\n",
    "            f1 = f1_score(y_test, y_test_pred)\n",
    "            \n",
    "            # Update best model info\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_model = lr\n",
    "                best_vectorizer = vectorizer\n",
    "                best_conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "                best_params = {\"C\": C, \"penalty\": penalty}\n",
    "    \n",
    "    # Calculate average times\n",
    "    avg_fit_time = total_fit_time / num_iterations\n",
    "    avg_test_time = total_test_time / num_iterations\n",
    "    \n",
    "    print(f\"\\nResults for {dataset_name} Corpus:\")\n",
    "    print(f\"Best F1 Score (C={best_params['C']}, penalty={best_params['penalty']}): {best_f1:.4f}\")\n",
    "    print(f\"Average Fit Time: {avg_fit_time:.4f} s\")\n",
    "    print(f\"Average Test Time: {avg_test_time:.4f} s\")\n",
    "    print(\"Confusion Matrix for Best Model:\\n\", best_conf_matrix)\n",
    "    \n",
    "    return best_model, best_vectorizer\n",
    "\n",
    "# Run evaluation for both datasets and store best models\n",
    "best_model_original, best_vectorizer_original = run_logistic_regression(\n",
    "    original_corpus['text'], original_corpus['label'], \"Original\"\n",
    ")\n",
    "best_model_cleaned, best_vectorizer_cleaned = run_logistic_regression(\n",
    "    cleaned_corpus['text'], cleaned_corpus['label'], \"Cleaned\"\n",
    ")\n",
    "\n",
    "# Analyze coefficients for both models\n",
    "analyze_coefficients(best_model_original, best_vectorizer_original, \"Original\")\n",
    "analyze_coefficients(best_model_cleaned, best_vectorizer_cleaned, \"Cleaned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d66848-b425-4264-8799-6b80af0bb75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
