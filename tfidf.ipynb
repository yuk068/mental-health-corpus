{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c752c73a-db80-4288-b808-79428c06cc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Cleaned Corpus (23240, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cleaned_corpus = pd.read_csv('data/cleaned_mhc.csv')\n",
    "\n",
    "print(\"Shape of Cleaned Corpus\", cleaned_corpus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dea9b498-cb5c-4825-9050-00277e70f66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 sample:\n",
      "recently ive eating stomach problem im getting really bad stomach pain im hungry appetite throw little food eat think eating disorder something im sure\n",
      "\n",
      "TF-IDF values:\n",
      "    Token   TF-IDF\n",
      "  stomach 0.514720\n",
      "   eating 0.434127\n",
      "   hungry 0.286663\n",
      "    throw 0.235316\n",
      " disorder 0.226459\n",
      "       im 0.225463\n",
      "     food 0.214009\n",
      "      eat 0.211527\n",
      " recently 0.184122\n",
      "  problem 0.158726\n",
      "     pain 0.154161\n",
      "     sure 0.152481\n",
      "   little 0.150323\n",
      "  getting 0.141145\n",
      "      bad 0.135555\n",
      "something 0.126122\n",
      "      ive 0.106503\n",
      "    think 0.105709\n",
      "   really 0.104681\n",
      "\n",
      "Vector statistics:\n",
      "Non-zero values: 19\n",
      "Zero values: 3481\n",
      "Total vector length: 3500\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 0 sample:\n",
      "come rteenagers let people farm karma make post making fun karma get deleted karma ridiculous let meme ugh\n",
      "\n",
      "TF-IDF values:\n",
      "     Token   TF-IDF\n",
      "     karma 0.730628\n",
      "       let 0.266933\n",
      "       ugh 0.264021\n",
      "rteenagers 0.249057\n",
      "ridiculous 0.238737\n",
      "   deleted 0.238392\n",
      "      meme 0.215462\n",
      "       fun 0.159209\n",
      "    making 0.144351\n",
      "      post 0.135817\n",
      "      come 0.124612\n",
      "      make 0.093020\n",
      "    people 0.088661\n",
      "       get 0.079184\n",
      "\n",
      "Vector statistics:\n",
      "Non-zero values: 14\n",
      "Zero values: 3486\n",
      "Total vector length: 3500\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 0 sample:\n",
      "im true nerf war veteran im real even call pro use poop battle cum substitute bullet\n",
      "\n",
      "TF-IDF values:\n",
      "  Token   TF-IDF\n",
      "veteran 0.431727\n",
      "    pro 0.401784\n",
      " bullet 0.380166\n",
      " battle 0.335614\n",
      "    war 0.316871\n",
      "   true 0.265478\n",
      "    use 0.247315\n",
      "   call 0.233658\n",
      "   real 0.221305\n",
      "     im 0.202540\n",
      "   even 0.135550\n",
      "\n",
      "Vector statistics:\n",
      "Non-zero values: 11\n",
      "Zero values: 3489\n",
      "Total vector length: 3500\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 0 sample:\n",
      "day guess song added word today ill add another word tommorow maybe winner today let\n",
      "\n",
      "TF-IDF values:\n",
      "  Token   TF-IDF\n",
      "   word 0.469420\n",
      " winner 0.398136\n",
      "  today 0.385011\n",
      "  added 0.333273\n",
      "    add 0.287685\n",
      "   song 0.274502\n",
      "  guess 0.211207\n",
      "another 0.194518\n",
      "    let 0.191901\n",
      "  maybe 0.191363\n",
      "    ill 0.172067\n",
      "    day 0.134964\n",
      "\n",
      "Vector statistics:\n",
      "Non-zero values: 12\n",
      "Zero values: 3488\n",
      "Total vector length: 3500\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 0 sample:\n",
      "cool fact house cat god bone crushed god help hear demon scream god look eye\n",
      "\n",
      "TF-IDF values:\n",
      "  Token   TF-IDF\n",
      "    god 0.595765\n",
      "crushed 0.298841\n",
      "   bone 0.298317\n",
      "  demon 0.295297\n",
      " scream 0.272165\n",
      "    cat 0.245386\n",
      "   cool 0.228672\n",
      "    eye 0.205675\n",
      "   hear 0.204479\n",
      "   fact 0.185619\n",
      "  house 0.185360\n",
      "   look 0.157061\n",
      "   help 0.124058\n",
      "\n",
      "Vector statistics:\n",
      "Non-zero values: 13\n",
      "Zero values: 3487\n",
      "Total vector length: 3500\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 1 sample:\n",
      "really want die also dont want leave anyone behind know wouldnt make really suicidal worse\n",
      "\n",
      "TF-IDF values:\n",
      "   Token   TF-IDF\n",
      " wouldnt 0.398240\n",
      "  really 0.364489\n",
      "  behind 0.352312\n",
      "    want 0.304147\n",
      "   leave 0.290301\n",
      "   worse 0.273270\n",
      "suicidal 0.271695\n",
      "     die 0.231617\n",
      "    also 0.230504\n",
      "  anyone 0.222146\n",
      "    dont 0.211612\n",
      "    make 0.186051\n",
      "    know 0.153725\n",
      "\n",
      "Vector statistics:\n",
      "Non-zero values: 13\n",
      "Zero values: 3487\n",
      "Total vector length: 3500\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 1 sample:\n",
      "want anyone try help want die want die people give shit would fuckin life one decides die\n",
      "\n",
      "TF-IDF values:\n",
      "  Token   TF-IDF\n",
      "    die 0.552861\n",
      " fuckin 0.405786\n",
      "decides 0.390141\n",
      "   want 0.362994\n",
      "   shit 0.194371\n",
      "   give 0.194101\n",
      "    try 0.193930\n",
      " anyone 0.176752\n",
      "   help 0.163358\n",
      "  would 0.144864\n",
      " people 0.141096\n",
      "    one 0.131218\n",
      "   life 0.128862\n",
      "\n",
      "Vector statistics:\n",
      "Non-zero values: 13\n",
      "Zero values: 3487\n",
      "Total vector length: 3500\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 1 sample:\n",
      "even fucking know anymoremy grade failing relationship family abusive want live anymore keep trying best never work\n",
      "\n",
      "TF-IDF values:\n",
      "       Token   TF-IDF\n",
      "     failing 0.383907\n",
      "     abusive 0.378687\n",
      "       grade 0.332009\n",
      "relationship 0.283297\n",
      "      trying 0.243750\n",
      "        best 0.237846\n",
      "     fucking 0.233226\n",
      "        keep 0.229988\n",
      "        work 0.219751\n",
      "        live 0.218817\n",
      "      family 0.216800\n",
      "     anymore 0.210811\n",
      "       never 0.190571\n",
      "        even 0.168312\n",
      "        know 0.147742\n",
      "        want 0.146155\n",
      "\n",
      "Vector statistics:\n",
      "Non-zero values: 16\n",
      "Zero values: 3484\n",
      "Total vector length: 3500\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 1 sample:\n",
      "cant muster courage kill day want jump skin life torturing day every day cant possibly make another week want die soo badly im really scared\n",
      "\n",
      "TF-IDF values:\n",
      "   Token   TF-IDF\n",
      "     day 0.380921\n",
      "     soo 0.368451\n",
      "    skin 0.293777\n",
      "possibly 0.285964\n",
      " courage 0.273757\n",
      "   badly 0.269823\n",
      "    jump 0.268523\n",
      "    cant 0.246963\n",
      "    want 0.205696\n",
      "  scared 0.199642\n",
      " another 0.183001\n",
      "    week 0.175897\n",
      "    kill 0.158003\n",
      "     die 0.156644\n",
      "   every 0.152545\n",
      "    make 0.125828\n",
      "  really 0.123253\n",
      "    life 0.109533\n",
      "      im 0.088487\n",
      "\n",
      "Vector statistics:\n",
      "Non-zero values: 19\n",
      "Zero values: 3481\n",
      "Total vector length: 3500\n",
      "\n",
      "==================================================\n",
      "\n",
      "Class 1 sample:\n",
      "gun redflag killed boyfriend gun would get trouble law im considering option want cause legal problem im gone\n",
      "\n",
      "TF-IDF values:\n",
      "      Token   TF-IDF\n",
      "        gun 0.503507\n",
      "      legal 0.332282\n",
      "        law 0.313152\n",
      "considering 0.269671\n",
      "    trouble 0.266998\n",
      "     killed 0.243685\n",
      "     option 0.241319\n",
      "  boyfriend 0.234734\n",
      "      cause 0.221689\n",
      "       gone 0.204241\n",
      "    problem 0.187572\n",
      "         im 0.177625\n",
      "    redflag 0.161851\n",
      "      would 0.123587\n",
      "        get 0.107506\n",
      "       want 0.103226\n",
      "\n",
      "Vector statistics:\n",
      "Non-zero values: 16\n",
      "Zero values: 3484\n",
      "Total vector length: 3500\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=3500)\n",
    "\n",
    "# Fit TF-IDF vectorizer\n",
    "X = vectorizer.fit_transform(cleaned_corpus['text'])\n",
    "\n",
    "# Get samples from each class\n",
    "class_0 = cleaned_corpus[cleaned_corpus['label'] == 0]\n",
    "class_1 = cleaned_corpus[cleaned_corpus['label'] == 1]\n",
    "\n",
    "# Filter samples by token length\n",
    "mask_0 = class_0['text'].str.split().str.len().between(15, 25)\n",
    "mask_1 = class_1['text'].str.split().str.len().between(15, 25)\n",
    "\n",
    "samples_0 = class_0[mask_0].sample(n=5, random_state=42)\n",
    "samples_1 = class_1[mask_1].sample(n=5, random_state=42)\n",
    "\n",
    "samples = pd.concat([samples_0, samples_1])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "vector_length = len(feature_names)\n",
    "\n",
    "for idx, row in samples.iterrows():\n",
    "    print(f\"Class {row['label']} sample:\")\n",
    "    print(f\"{row['text']}\\n\")\n",
    "    \n",
    "    print(\"TF-IDF values:\")\n",
    "    sample_vector = vectorizer.transform([row['text']])\n",
    "    vector_array = sample_vector.toarray()[0]\n",
    "    nonzero_mask = vector_array != 0\n",
    "    nonzero_values = pd.DataFrame({\n",
    "        'Token': feature_names[nonzero_mask],\n",
    "        'TF-IDF': vector_array[nonzero_mask]\n",
    "    })\n",
    "    nonzero_values = nonzero_values.sort_values('TF-IDF', ascending=False)\n",
    "    print(nonzero_values.to_string(index=False))\n",
    "    \n",
    "    n_nonzero = np.count_nonzero(vector_array)\n",
    "    n_zero = vector_length - n_nonzero\n",
    "    print(f\"\\nVector statistics:\")\n",
    "    print(f\"Non-zero values: {n_nonzero}\")\n",
    "    print(f\"Zero values: {n_zero}\")\n",
    "    print(f\"Total vector length: {vector_length}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
